<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Academic Notes</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://wym0120.github.io/"/>
  <updated>2021-04-12T15:24:42.751Z</updated>
  <id>https://wym0120.github.io/</id>
  
  <author>
    <name>MinguW</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>[课堂笔记] 软件过程改进</title>
    <link href="https://wym0120.github.io/2021/04/12/cmmi/"/>
    <id>https://wym0120.github.io/2021/04/12/cmmi/</id>
    <published>2021-04-12T15:24:08.000Z</published>
    <updated>2021-04-12T15:24:42.751Z</updated>
    
    <content type="html"><![CDATA[]]></content>
    
    <summary type="html">
    
      软件过程改进课堂笔记
    
    </summary>
    
    
    
      <category term="lecture" scheme="https://wym0120.github.io/tags/lecture/"/>
    
  </entry>
  
  <entry>
    <title>[ISER] [STA] Bugs as deviant behavior: A general approach to inferring errors in systems code</title>
    <link href="https://wym0120.github.io/2021/04/12/paper/ISER/Software%20Testing%20and%20Analysis/sta-2/"/>
    <id>https://wym0120.github.io/2021/04/12/paper/ISER/Software%20Testing%20and%20Analysis/sta-2/</id>
    <published>2021-04-12T15:01:26.110Z</published>
    <updated>2021-04-12T15:01:26.110Z</updated>
    
    <content type="html"><![CDATA[<h3 id="abstract">Abstract</h3><blockquote><p>A major obstacle to finding program errors in a real system is knowing what correctness rules the system must obey. These rules are often undocumented or specified in an ad hoc manner. This paper demonstrates techniques that automatically extract such checking information from the source code itself, rather than the programmer, thereby avoiding the need for a priori knowledge of system rules.</p></blockquote><blockquote><p>The cornerstone of our approach is inferring programmer "beliefs" that we then crosscheck for contra dictions. Beliefs are facts implied by code: a dereference of a pointer, p, implies a belief that p is nonnull, a call to "tmlock(1)" implies that 1 was locked, etc. For be liefs we know the programmer must hold, such as the pointer dereference above, we immediately flag contra dictions as errors. For beliefs that the programmer may hold, we can assume these beliefs hold and use a statistical analysis to rank the resulting errors from most to least likely. For example, a call to "spin_lock" followed once by a call to "spin_tmlock" implies that the programmer may have paired these calls by coincidence.</p></blockquote><blockquote><p>If the pairing happens 999 out of 1000 times, though, then it is probably a valid belief and the sole deviation a probable error. The key feature of this approach is that it requires no a priori knowledge of truth: if two beliefs contradict, we know that one is an error without knowing what the correct belief is. Conceptually, our checkers extract beliefs by tailor ing rule "templates" to a system for example, finding all functions that fit the rule template "&lt;a&gt; must be paired with &lt; b&gt;." We have developed six checkers that follow this conceptual framework. They find hundreds of bugs in real systems such as Linux and OpenBSD. From our experience, they give a dramatic reduction in the manual effort needed to check a large system. Com pared to our previous work , these template checkers find ten to one hundred times more rule instances and derive properties we found impractical to specify manually.</p></blockquote><h3 id="总体评价">总体评价</h3><h3 id="motivation">Motivation</h3><p>这篇文章基于的一个假设是人是很难寻找和归纳出对于一个程序什么是必须遵循的正确的法则，什么是应该遵循的法则。这并不是指人不能总结出一些法则，而是说在编码过程中很难强制机器去遵守。因此，希望能够自动提取出某段特定代码应该有什么样的约束，例如在使用指针的时候指针指向的对象必须非空，例如lock和unlock应该要成对出现。而在静态检查的过程中如果发现代码违背了这些最基本的一些应该遵守的法则，那么就认为是一个可能的错误。 ### Evalution</p><h3 id="details">Details</h3>]]></content>
    
    <summary type="html">
    
      Dawson Engler, David Yu Chen, Seth Hallem, Andy Chou, and Benjamin Chelf. Bugs as deviant behavior: A general approach to inferring errors in systems code. SOSP&#39;01
    
    </summary>
    
    
      <category term="paper" scheme="https://wym0120.github.io/categories/paper/"/>
    
    
      <category term="Software Testing and Analysis" scheme="https://wym0120.github.io/tags/Software-Testing-and-Analysis/"/>
    
  </entry>
  
  <entry>
    <title>How to write and publish technical papers in English</title>
    <link href="https://wym0120.github.io/2021/04/08/report/english-writing/"/>
    <id>https://wym0120.github.io/2021/04/08/report/english-writing/</id>
    <published>2021-04-08T08:00:41.000Z</published>
    <updated>2021-04-12T15:01:26.111Z</updated>
    
    <content type="html"><![CDATA[<h3 id="paper">Paper</h3><h4 id="title">Title</h4><ul><li>Use fewest possible words</li><li>Adequately describe the contents of the paper</li><li>To be read by thousands of people. Few may read the entire paper.</li><li>Choose all words in the title with great care</li><li>Carefully manage their association from one with each other</li></ul><h4 id="abstract">Abstract</h4><ul><li>A sumary of the information in a document</li><li>A single paragraph of 100-200 words</li><li>Self contained, no bibliographic, figure, or table references</li><li>No obscure abbreviations and acronyms</li><li>Write the paper before writing the Abstarct</li></ul><h4 id="introduction">Introduction</h4><ul><li>Answer the question "What was the problem?" Why is it important</li><li>Supply sufficient background information to allow the reader to understand and evaluate the results of the present study without needing to refer to previous on the topic.</li><li>Provide the rationale for the present study (e.g. a motivating example).</li><li>State briefly and clearly your purpose in writing the paper and <strong>your contributions</strong>.</li><li>Choose references carefully to provide the most important background infomation.</li></ul><h4 id="results">Results</h4><ul><li>Answer the question "What did you find?"</li><li>Experimental performance evaluation for system work</li><li>Empirical study for user interaction work</li><li>Complexity analysis for algorithm work</li><li>Case studies with real world applications</li></ul><h4 id="discussion">Discussion</h4><ul><li>Answer the question "What do these findings mean?"</li></ul><h4 id="related-work">Related Work</h4><ul><li>Review most relevant work</li><li>Comment on the similarity and differences of your work from them</li><li>What makes your work unique and worth doing?</li><li>Usually as Section 2, or second last section</li></ul><h4 id="conclusion-and-future-work">Conclusion and Future Work</h4><ul><li>Answer the question "What do you conclude?"</li><li>What actions need to be taken as future work?</li><li>Any discussion of controversial issues</li></ul><h4 id="acknowledgements">Acknowledgements</h4><ul><li>Give credit to individuals who have helped you</li><li>Acknowledge funding agencies that have partially supported your work</li></ul><h4 id="references">References</h4><ul><li>Use statndard bibliographic style</li><li>Be complete and consistent with sytle</li><li>Use more recent and more influential papers</li></ul><h3 id="practices">Practices</h3><ul><li>Read as many good papers as possible</li><li><strong>Adapt</strong> good sense of writing from good papers</li><li>Write as many papers (in English) as possible</li><li>Be serious with reviewers' comments and learn from them</li><li>Collaborate with other researchers</li><li>Volunteer to review papers</li></ul><h3 id="specific-rules">Specific Rules</h3><ul><li>A sentence should be under 3 lines in a single column or 5 lines in a double-column.</li><li>Without comparison, do not use "more" or "less"</li><li>Issues on passive voice ...<ul><li>避免被动语态除非主语很明确，可以给系统一个名字让系统作为主语</li><li>不要总是用 "we"，可以加上半句 "Having done this, we decide ..."</li></ul></li><li>Issues on tense ...<ul><li>过去时态用于描述过去的一个工作</li><li>将来时态只用在 future work 中</li><li>完成时只用在 conclusion 中</li></ul></li><li>Typical Chinglish<ul><li>A lot of -&gt; <strong>Many or Much</strong></li><li>Actually -&gt; <strong>In fact</strong></li><li>Based on -&gt; <strong>unnecessary in many contexts</strong></li><li>Be considered as -&gt; <strong>Be considered</strong></li><li>Besides -&gt; <strong>Apart from (和 Except 不一样，后者是不包含， Except for 也是错误用法)</strong></li><li>Especially -&gt; <strong>Particularly, or In particular</strong></li><li>Firstly, ..., Secondly -&gt; <strong>First, ..., Second -&gt; Bullet list</strong></li><li>For "A" (noun), we (verb) it -&gt; <strong>We (verb) "A"</strong></li><li>Kind of -&gt; <strong>Type of</strong></li><li>Not only A, but also B -&gt; <strong>除非真的想强调A和B不可或缺且互补，否则用and</strong></li><li>Painted with red color -&gt; <strong>Colored red</strong></li><li>Researches -&gt; <strong>只有 Researchers 或者 Research</strong></li><li>Some -&gt; <strong>你想说某些，因为你不知道哪些，所以delete它 (避免不能精确的字)</strong></li><li>Very -&gt; <strong>delete it!</strong></li><li>Want -&gt; <strong>Wish</strong></li><li>We can see from Figure X that -&gt; <strong>Figure X shows that</strong></li><li>Whole -&gt; <strong>Entire</strong></li></ul></li><li>Common Phrases and Suggested Subsitutes<ul><li>For the reason why -&gt; <strong>Why</strong></li><li>Starting a sentence with "And" -&gt; <strong>delete "And"</strong></li><li>The authors are unaware of the fact that -&gt; <strong>The authors are unaware that</strong></li><li>Their alogorithm is a fast one -&gt; <strong>Their alogorithm is fast</strong></li><li>Try to -&gt; <strong>Attempt to</strong></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      How to write and publish technical papers in English
    
    </summary>
    
    
    
      <category term="writing" scheme="https://wym0120.github.io/tags/writing/"/>
    
      <category term="english" scheme="https://wym0120.github.io/tags/english/"/>
    
  </entry>
  
  <entry>
    <title>[Lecture Notes] Software Architecture</title>
    <link href="https://wym0120.github.io/2020/12/17/lecture/software-architecture/SA-notes/"/>
    <id>https://wym0120.github.io/2020/12/17/lecture/software-architecture/SA-notes/</id>
    <published>2020-12-17T10:39:11.000Z</published>
    <updated>2021-04-12T15:01:26.107Z</updated>
    
    <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2><p>科学和工程的本质区别：是否有人的参与。工程的本质上是改变这个世界</p><p>软件架构两个定义之间的区别与联系：SEI和IEEE的定义基本相同，IEEE更为宽泛，而多的定义是与外部环境的交互以及设计演进的指导原则。</p><p>为什么在设计当中需要抽象？</p><p>Use Case 会把四个视图结合起来</p><h2 id="chapter1">chapter1</h2><p>正确的设计顺序： constarins -&gt; quality attributes -&gt; functionalty attributes</p><h3 id="quality-attributes-and-tactics">Quality Attributes And Tactics</h3><h4 id="availability">Availability</h4><p>描述 availability -&gt; 使用时间</p><p>------------------------------------------------&gt; timeline ↑ ↑ ↑ ↑ failure detect correct restart Mean time between failures : restart - failure 高可用性：上面的三段时间都尽可能的小 -&gt; 缩短这些时间都可以提高可用性</p><h5 id="缩短检测时间">缩短检测时间：</h5><p>什么情况下使用ping/echo，什么情况下使用heartbeat? &gt; ping echo是双向的，heartbeat是单向的 &gt; 尽管heartbeat带宽更小，但是需要一直占用着资源，多用于长时间始终保持连接的，实时的监控 &gt; ping是只有需要的时候才去ping，不会始终占用着资源</p><p>volting:用三个detect技术来保持一致，这些detect可以用同样的实现也可以是不同的实现</p><h5 id="缩短恢复时间">缩短恢复时间</h5><p>假设有两台机器，一台是primary / secondary Active redundancy / passive redundancy / spare active : 两个都在运行，随时可以切换，两台都进行同样的工作，只是忽略备用的输出 passive : 备用机器定期同步，开着但是不会进行相同的工作 spare : 定期打primary的快照，down了之后在secondary上恢复 这三个时间会逐渐变长（本质是资源换时间） #### Reliability</p>]]></content>
    
    <summary type="html">
    
      软件体系结构课堂笔记
    
    </summary>
    
    
    
      <category term="lecture notes" scheme="https://wym0120.github.io/tags/lecture-notes/"/>
    
  </entry>
  
  <entry>
    <title>transwarp-QA</title>
    <link href="https://wym0120.github.io/2020/12/08/transwarp/"/>
    <id>https://wym0120.github.io/2020/12/08/transwarp/</id>
    <published>2020-12-08T14:42:56.000Z</published>
    <updated>2021-04-12T15:01:26.113Z</updated>
    
    <content type="html"><![CDATA[<h3 id="练习题库一">练习题库(一)</h3><ol type="1"><li><p>在 HDFS 服务中，为了保证 Name Node 高可用性的角色不包括 A. Data Node☑️ B. Journal Node C. ZKFC D. Zookeeper</p></li><li><p>Namenode 在启动时自动进入安全模式，在安全模式阶段，说法错误的是 A. 安全模式目的是在系统启动时对数据有效性进行检查 B. 根据策略对数据块进行必要的复制或删除 C. 当数据块的上报数达到阈值时，会自动退出安全模式 D. 允许用户对文件系统进行读写操作☑️</p></li><li><p>在集群中配置 HDFS 的副本数为 3，设置数据块大小为 128M，此时我们上传一份 64M 的数据文件，该数据文件占用 HDFS 空间大小为 A. 64M B. 128M C. 384M☑️ D. 192M</p></li><li><p>下列对 YARN 角色在集群中的作用描述正确的是 A. 集群资源管理☑️ B. 集群任务调度与管理☑️ C. 存储部分 HDFS 上的数据块 D. 以上都正确</p></li><li><p>在 Yarn 服务中，不包含以下哪种角色 A. ResourceManager B. NodeManager C. ApplicationMaster D. Contianer☑️</p></li><li><p>下列计算框架中不属于分布式计算框架的是 A. MapReduce B. MATLAB☑️ C. SPARK D. Tez</p></li><li><p>以下关于外表和托管表描述正确的是 A. 外表的数据存储在本地，托管表的数据存储在 hdfs 上 B. 删除托管表只会删除 Inceptor 上的元数据不会删除数据文件，删除外表两者都会 被删除 C. 删除外表只会删除 Inceptor 上的元数据不会删除数据文件，删除托管表两者都会 被删除☑️ D. 删除托管表或外表，incepotr 上的元数据和数据文件都会被删除</p></li><li><p>以下对分桶表的描述正确的是 A. 分桶表通过改变数据的存储分布，对查询起到一定的优化作用☑️ B. 分桶键不能是表中的列 C. 分桶数应为素数 D. 事物表必须制定分桶，分桶字段可以被更新</p></li><li><p>以下关于 inceptor excutor 资源配置的说法正确的有 A. Excutor 资源配置 fixed 和 ratio 两种模式☑️ B. Excutor 内核数配置的是每个 excutor 所使用的逻辑 core 数量☑️ C. Excutor 内核数和内存配置比例一般为 1 core:2G memory☑️ D. Excutor 分布可以指定每个节点运行的 excutor 数量或 executor 在集群上运行的 总数量，但是不能指定运行的节点</p></li><li><p>假设使用场景中有如下查询语句 <figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> Sex, Region, <span class="keyword">COUNT</span>(<span class="keyword">ID</span>), <span class="keyword">AVG</span> (Salary)</span><br><span class="line"><span class="keyword">FROM</span> Employee</span><br><span class="line"><span class="keyword">WHERE</span> Department = <span class="string">&#x27;IT&#x27;</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> Sex, Region</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> Sex, Region;</span><br></pre></td></tr></table></figure> 通过 holodesk 的 cube 和 index 手段对这种过滤率和聚合率高的业务进行优化，以下建表 正确的是 <figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">A.☑️ <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> Employee</span><br><span class="line">TBLPROPERTIES (</span><br><span class="line"><span class="string">&#x27;cache&#x27;</span> = <span class="string">&#x27;RAM&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.index&#x27;</span> = <span class="string">&#x27;Department&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.dimension&#x27;</span> = <span class="string">&#x27;Sex, Region&#x27;</span>)</span><br><span class="line"></span><br><span class="line">B. <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> Employee</span><br><span class="line">TBLPROPERTIES (</span><br><span class="line"><span class="string">&#x27;cache&#x27;</span> = <span class="string">&#x27;RAM&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.index&#x27;</span> = <span class="string">&#x27;Sex, Region&#x27;</span></span><br><span class="line"><span class="string">&#x27;holodesk.dimension&#x27;</span> = <span class="string">&#x27;Department&#x27;</span> )</span><br><span class="line"></span><br><span class="line">C. <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> Employee TBLPROPERTIES (</span><br><span class="line"><span class="string">&#x27;cache&#x27;</span> = <span class="string">&#x27;&#x27;</span>Department<span class="string">&#x27;&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.index&#x27;</span> = <span class="string">&#x27;Department&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.dimension&#x27;</span> = <span class="string">&#x27;Sex, Region&#x27;</span>)</span><br><span class="line"></span><br><span class="line">D. <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> Employee TBLPROPERTIES (</span><br><span class="line"><span class="string">&#x27;cache&#x27;</span> = <span class="string">&#x27;RAM&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.index&#x27;</span> = <span class="string">&#x27;Department&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.dimension&#x27;</span> = <span class="string">&#x27;Sex&#x27;</span> )</span><br></pre></td></tr></table></figure></p></li><li><p>关于 Hyperbase 全局索引的描述，哪些是正确的？ A. 核心是倒排表☑️ B. 全局索引概念是对应 Rowkey 这个“一级”索引☑️ C. 全局索引使用平衡二叉树 D. 全局索引使用 B+树检索数据☑️</p></li><li><p>以下为 Hyperbase 分布式存储的最小单元的是 A. Region server B. Region☑️ C. StoreFile D. Store</p></li><li><p>以下有关 Hyperbase 说法正确的是 A. 数据类型丰富，支持 String. Int. Char 等类型 B. Key/value 系统，key 由 Row,Column Family,Column Qualifier 组成 C. Hyperbase 表中 rowkey 有序，按字典序降序排列 D. 以上说法都不正确☑️</p></li><li><p>以下关于 StreamSQL 的概念描述正确的是 A. Stream 是数据流☑️ B. Streamjob 是对一个或多个 stream 进行计算并将结果写进一个流的任务 C. Application 是一个或多个 streamjob 的集合☑️ D. 以上说法都不正确</p></li><li><p>某交通部门通过使用流监控全市过往 24 小时各个卡口数据，要求每分钟更新一次， 原始流为 org_stream，以下实现正确的是 <figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">A. <span class="keyword">CREATE</span> STREAMWINDOW traffic_stream <span class="keyword">AS</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> original_stream</span><br><span class="line">STREAM w1 <span class="keyword">AS</span> (<span class="keyword">length</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">minute</span> slide <span class="string">&#x27;24&#x27;</span> <span class="keyword">hour</span>);</span><br><span class="line">B. <span class="keyword">CREATE</span> STREAM traffic_stream <span class="keyword">AS</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> original_stream</span><br><span class="line">STREAMWINDOW w1 <span class="keyword">AS</span> (<span class="keyword">length</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">minute</span> slide <span class="string">&#x27;24&#x27;</span> <span class="keyword">hour</span>);</span><br><span class="line">C.☑️ <span class="keyword">CREATE</span> STREAM traffic_stream <span class="keyword">AS</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> original_stream</span><br><span class="line">STREAMWINDOW w1 <span class="keyword">AS</span> (<span class="keyword">length</span> <span class="string">&#x27;24&#x27;</span> <span class="keyword">hour</span> slide <span class="string">&#x27;1&#x27;</span> <span class="keyword">minute</span>);</span><br><span class="line">D. <span class="keyword">CREATE</span> STREAM traffic_stream <span class="keyword">AS</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> original_stream <span class="keyword">AS</span> (<span class="keyword">length</span> <span class="string">&#x27;24&#x27;</span></span><br><span class="line"><span class="keyword">second</span> slide <span class="string">&#x27;1&#x27;</span> <span class="keyword">minute</span>);</span><br></pre></td></tr></table></figure></p></li><li><p>以下不是 Zookeeper 的功能是 A. 配置管理 B. 集群管理 C. 分布式锁 D. 存储大量数据☑️</p></li><li><p>以下服务需要与 zookeeper 进行通信的是 A. HMaster B. Active NameNode C. InceptorSQL D. Active ResourceManager☑️</p></li><li><p>下列是关于 flume 和 sqoop 对比的描述，不正确的是 A. flume 主要用来采集日志而 sqoop 主要用来做数据迁移 B. flume 主要采集流式数据而 sqoop 主要用来迁移规范化数据☑️ C. flume 和 sqoop 都是分布式处理任务☑️ D. flume 主要用于采集多数据源小数据而 sqoop 用来迁移单数据源数据</p></li><li><p>有关使用 sqoop 抽取数据的原理的描述不正确的是 A. sqoop 在抽取数据的时候可以指定 map 的个数，map 的个数决定在 hdfs 生成的 数据文件的个数 B. sqoop 抽取数据是个多节点并行抽取的过程，因此 map 的个数设置的越多性能越好☑️ C. sqoop 任务的切分是根据 split 字段的（最大值-最小值）/map 数 D. sqoop 抽取数据的时候需要保证执行当前用户有权限执行相应的操作</p></li><li><p>sqoop 抽取数据时需要做一些数据转换的工作，下面说法不正确的是 A. --fields-terminated-by '\01' 用来设置在 hdfs 生成的文件的分割符 B. --hive-drop-import-delims 用来设置在 hdfs 生成的文件的存储形式为列存储☑️ C. --null-string '\N' 用来把所有的 String 类型的空值 转换成 hive 的 NULL 值 D. --null-non-string '\N' 用来把非 String 类型的空值 转换成 hive 的 NULL 值</p></li><li><p>下列有关 flume 的描述不正确的是 A. flume 是 Apache 的一个子项目 B. flume 主要是一个日志采集，传输系统 C. flume 和 sqoop 功能相似，因此可以相互替代☑️ D. flume 可以同时采集集群内部和集群外部的日志数据</p></li><li><p>下列 sink 中哪些是 flume 不支持的 sink A. HDFS sink B. kafka sink C. memory sink☑️ D. file roll sink</p></li><li><p>以下对 ElasticSearch 描述不正确的是 A. ElasticSearch 是分布式全文搜索引擎 B. ElasticSearch 集群中分 master 和 data 节点 C. ElasticSearch 数据存储在 HDFS 上☑️ D. ElasticSearch 数据可以按 Shard 分布在不同的节点上</p></li><li><p>下列不属于 kafka 应用场景的是 A. 常规的消息收集 B. 网站活动性跟踪 C. 日志收集 D. 关系型数据库和大数据平台之间的数据迁移☑️</p></li><li><p>TDH 提供哪几种认证模式？ A. 所有服务使用简单认证模式——所有服务都无需认证即可互相访问☑️ B. 所有服务都启用 Kerberos 认证，用户要提供 Kerberos principal 和密码（或者keytab）来访问各个服务☑️ C. 所有服务都启用 Kerberos 同时 Inceptor 启用 LDAP 认证☑️ D. 所有服务都启用 LDAP 认证</p></li><li><p>以下对各组件的运维页面描述不正确的是 A. 通过 Name Node 的 50070 页面对 HDFS 进行监控 B. 通过 Resource Manager 的 8180 对 YARN 上运行的任务进行监控☑️ C. 通过 HMaster 的 60010 对 HBase 进行监控☑ D. 通过 Hue Server 的 8888 页面登入 Hue</p></li><li><p>Inceptor server 服务无法启动时，该如何查看日志是 A. 查看 TDH manager 所在节点/var/log/inceptorsql<em>/目录下的 hive-server2.log 日志 B. 查看 Inceptor server 所在节点/var/log/inceptorsql</em>/目录下的 hive-server2.log 日志☑️ C. 查 看 Resource Manager 所 在 节 点 /var/log/Yarn<em>/ 目 录 下 的 yarn-yarn-resourcemanager-poc-node1.log 日志 D. 查看任意节点/var/log/inceptorsql</em>/目录下的 hive-server2.log 日志</p></li><li><p>以下对 Hadoop 组件的应用场景描述正确的是 A. Hive 主要用于构建大数据数仓，主要做批处理. 统计分析型业务☑️ B. Hbase 主要用于检索查询的 OLTP 业务☑️ C. ElasticSearch 主要用于全文检索的关键字查询业务☑️ D. Spark Streaming 主要用于实时数据的业务场景☑️</p></li><li><p>以下不属于管理角色的是 A. Name Node B. HMaster C. Resource Manager D. Node Manager☑️</p></li><li><p>下面哪些工作不属于集群预安装工作 A. 为集群中每个节点的安装操作系统 B. 选一个节点作为管理节点，修改其 /etc/hosts 文件 C. 安装 Transwarp Manager 管理界面 D. 配置集群安全模式☑️</p></li></ol><h3 id="练习题库二">练习题库(二)</h3><ol type="1"><li><p>下列与 HDFS 有关的说法正确的是 A. HDFS DataNode 节点上的磁盘需要做 RAID1，用来保证数据的可靠性 B. HDFS 可以在磁盘之间通过 balance 操作，平衡磁盘之间的负载情况 C. HDFS 建议 DataNode 之间的数据盘个数. 容量大小不一致，以体现 HDFS 的负均 衡能力 D. 规划 HDFS 集群时，建议 Active NameNode 和 Standby NameNode 分配在不同机 架上☑️</p></li><li><p>在 HDFS 服务中，为了保证 Name Node 高可用性的角色不包括 A. Data Node☑️ B. Journal Node C. ZKFC D. Zookeeper</p></li><li><p>在集群中配置 HDFS 的副本数为 3，设置数据块大小为 128M，此时我们上传一份 64M 的数据文件，该数据文件占用 HDFS 空间大小为 A. 64M B. 128M C. 384M☑️ D. 192M</p></li><li><p>在 Yarn 服务中，不包含以下哪种角色 A. ResourceManager B. NodeManager C. ApplicationMaster☑️ D. Contianer</p></li><li><p>下列有关 YRAN 中角色的描述不正确的是 A. ResourceManager 控制整个集群并管理基础计算资源的分配 B. NodeManager 管理每个节点的资源，管理抽象容器 C. NodeManager 负责调度当前节点的所有 ApplicationMaster☑️ D. ApplicationMaster 管理一个 YARN 内运行的应用程序的实例</p></li><li><p>Spark 与 MapReduce 对比，突出的优势不包括 A. 基于内存的计算，效率更高 B. Spark 能支持比 MapReduce 更多的应用场景 C. Spark 支持多种编程语言接口，框架开销更低 D. Spark 可以运行在 YARN 之上而 MapReduce 不能☑️</p></li><li><p>以下关于外表和托管表描述正确的是 A. 外表的数据存储在本地，托管表的数据存储在 hdfs 上 B. 删除托管表只会删除 Inceptor 上的元数据不会删除数据文件，删除外表两者都会 被删除 C. 删除外表只会删除 Inceptor 上的元数据不会删除数据文件，删除托管表两者都会 被删除☑️ D. 删除托管表或外表，incepotr 上的元数据和数据文件都会被删除</p></li><li><p>导入数据经常会用到 LOAD 命令，以下关于 LOAD 的描述错误的是 A. 源数据文件存放于 hdfs 上，通过 load 命令加载数据文件，数据文件将被复制到 表目录下☑️ B. 目标表为分桶表时不能通过 load 命令加载数据 C. 目标表为分区表时不能通过 load 命令加载数据 D. 当元数据存放于本地时，需要通过指定 LOCAL 关键字</p></li><li><p>tableA 有 10G 的数据，tableB 有 100G 的数据，两个表通过共有的 id 列做关联查询 name 列，以下方式可以优化计算效率的是 A. select /<em>+MAPJOIN(a)</em>/ a.name,b.name from tableA a join tableB b on a.id=b.id B. select /<em>+MAPJOIN(b)</em>/ a.name,b.name from tableA a join tableB b on a.id=b.id C. 建表时将 tableA 和 tableB 根据 id 字段分相同数量的桶☑️ D. 建表时将 tableA 和 tableB 根据 name 字段分相同数量的桶</p></li><li><p>假设使用场景中有如下查询语句 <figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> Sex, Region, <span class="keyword">COUNT</span>(<span class="keyword">ID</span>), <span class="keyword">AVG</span> (Salary)</span><br><span class="line"><span class="keyword">FROM</span> Employee</span><br><span class="line"><span class="keyword">WHERE</span> Department = <span class="string">&#x27;IT&#x27;</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> Sex, Region</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> Sex, Region;</span><br></pre></td></tr></table></figure> 通过 holodesk 的 cube 和 index 手段对这种过滤率和聚合率高的业务进行优化，以下建表 正确的是 <figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">A. ☑️<span class="keyword">CREATE</span> <span class="keyword">TABLE</span> Employee</span><br><span class="line">TBLPROPERTIES (</span><br><span class="line"><span class="string">&#x27;cache&#x27;</span> = <span class="string">&#x27;RAM&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.index&#x27;</span> = <span class="string">&#x27;Department&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.dimension&#x27;</span> = <span class="string">&#x27;Sex, Region&#x27;</span>)</span><br><span class="line"></span><br><span class="line">B. <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> Employee</span><br><span class="line">TBLPROPERTIES (</span><br><span class="line"><span class="string">&#x27;cache&#x27;</span> = <span class="string">&#x27;RAM&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.index&#x27;</span> = <span class="string">&#x27;Sex, Region&#x27;</span></span><br><span class="line"><span class="string">&#x27;holodesk.dimension&#x27;</span> = <span class="string">&#x27;Department&#x27;</span> )</span><br><span class="line"></span><br><span class="line">C. <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> Employee TBLPROPERTIES (</span><br><span class="line"><span class="string">&#x27;cache&#x27;</span> = <span class="string">&#x27;&#x27;</span>Department<span class="string">&#x27;&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.index&#x27;</span> = <span class="string">&#x27;Department&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.dimension&#x27;</span> = <span class="string">&#x27;Sex, Region&#x27;</span>)</span><br><span class="line"></span><br><span class="line">D. <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> Employee TBLPROPERTIES (</span><br><span class="line"><span class="string">&#x27;cache&#x27;</span> = <span class="string">&#x27;RAM&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.index&#x27;</span> = <span class="string">&#x27;Department&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.dimension&#x27;</span> = <span class="string">&#x27;Sex&#x27;</span> )</span><br></pre></td></tr></table></figure></p></li><li><p>关于 Hyperbase 全局索引的描述，哪些是正确的？ A. 核心是倒排表☑️ B. 全局索引概念是对应 Rowkey 这个“一级”索引☑️ C. 全局索引使用平衡二叉树 D. 全局索引使用 B+树检索数据☑️</p></li><li><p>以下不属于 Hyperbase 存储模型单位的是 A. table B. region☑️ C. StoreFile D. block</p></li><li><p>有关 Minor Compact 的描述正确的是 A. 一个 store 下的所有文件合并 B. 删除过期版本数据 C. 删除 delete marker 数据 D. 把多个 HFile 合成一个☑️</p></li><li><p>以下的 stream 的描述不正确的是 A. Input 定义了如何从数据源读取数据 B. Derived stream 是对 stream 转换而来的，可分为单 batch 变形和多 batch 变形 C. 定义 Derived stream 后 stream 当即根据转换规则进行变形☑️ D. 窗口变形的长度必须是当前流的整数倍</p></li><li><p>某公司有部门 A. 部门 B…，各部门的源数据都取自于企业总线，要求部门内部共享 数据源，部门间做到资源隔离，以下设计合理的有 A. 部门里每个流任务起一个 application 管理 streamjob B. 每个部门起一个 application 管理本部门的 streamjob☑️ C. 公司起一个 application 管理所有的 streamjob D. 每个部门起一个 streamjob 管理本部门的 application</p></li><li><p>Zookeeper 服务描述正确的是 A. Zookeeper 可以存储文件，所以它是用于存储大量数据信息的文件系统。 B. 它是集群的管理服务，总控节点间所有通信。 C. 它是分布式应用程序协调服务。☑️ D. 它是保存所有集群服务的元数据库。</p></li><li><p>我们可以通过 hue 图形化的操作 HDFS，hue 可以实现 hdfs 的 A. 创建目录☑️ B. 上传文件☑️ C. 直接查看文件☑️ D. 更改权限☑️</p></li><li><p>通过 oozie workflow 调度 sqoop 任务，以下说法正确的是 A. 必须使用 sudo 用户 B. 确保对应的 jdbc 驱动正确上传到 hdfs 上☑️ C. Sqoop 导入的 hdfs 目录必须前提不存在☑️ D. 以上说法都对</p></li><li><p>有关使用 sqoop 抽取数据的原理的描述不正确的是 A. sqoop 在抽取数据的时候可以指定 map 的个数，map 的个数决定在 hdfs 生成的 数据文件的个数 B. sqoop 抽取数据是个多节点并行抽取的过程，因此 map 的个数设置的越多性能 越好☑️ C. sqoop 任务的切分是根据 split 字段的（最大值-最小值）/map 数 D. sqoop 抽取数据的时候需要保证执行当前用户有权限执行相应的操作</p></li><li><p>有关 sqoop 的参数说法不正确的是 A. --username 是必需参数 B. --m 大于 1 时，--split-by 参数是必需参数 C. --query 是执行 sqoop 操作的必需参数☑️ D. --field-terminated-by 用来指定在 hdfs 生成数据文件时的列分隔符</p></li><li><p>下列是关于 flume 和 sqoop 对比的描述，不正确的是 A. flume 主要用来采集日志而 sqoop 主要用来做数据迁移 B. flume 主要采集流式数据而 sqoop 主要用来迁移规范化数据 C. flume 和 sqoop 都是分布式处理任务☑️ D. flume 主要用于采集多数据源小数据而 sqoop 用来迁移单数据源数据</p></li><li><p>以下不属于 Flume 的 Source 类型的是 A. exec source B. file source☑️ C. spooling directory source D. kafka source</p></li><li><p>有关 Elasticsearch 特性描述有误的一项是 A. 分布式实时文件存储，可将每一个字段存入索引 B. 实时分析的分布式搜索引擎。 C. 支持插件机制，分词插件. 同步插件 D. 以上都不正确☑️</p></li><li><p>下列不属于 kafka 应用场景的是 A. 常规的消息收集 B. 网站活动性跟踪 C. 日志收集 D. 关系型数据库和大数据平台之间的数据迁移☑️</p></li><li><p>TDH 提供哪几种认证模式？ A. 所有服务使用简单认证模式——所有服务都无需认证即可互相访问☑️ B. 所有服务都启用 Kerberos 认证，用户要提供 Kerberos principal 和密码（或者 keytab）来访问各个服务☑️ C. 所有服务都启用 Kerberos 同时 Inceptor 启用 LDAP 认证☑️ D. 所有服务都启用 LDAP 认证</p></li><li><p>在安装有 kerberos 服务的集群中如何切换用户 A. 不需要切换，所有用户都为服务公用用户，可以直接使用。 B. 直接使用 kinit 用户名称方式进行切换☑️ C. 必须先 destroy ，才能再使用 kinit 用户名称 方式登录 D. 以上都不正确</p></li><li><p>以下对 Transwarp Manager 描述不正确的是 A. Transwarp Manger 是 TDH 的管理运维平台 B. 通过 Transwarp Manager 的 8180 界面登入 C. 在 Transwarp Manager 上能启动和停止 Transwarp Agent 角色☑️ D. 在 Transwarp Manager 上能对 Inceptor 表进行赋权操作</p></li><li><p>以下对 Hadoop 组件的应用场景描述正确的是 A. Hive 主要用于构建大数据数仓，主要做批处理. 统计分析型业务☑️ B. Hbase 主要用于检索查询的 OLTP 业务☑️ C. ElasticSearch 主要用于全文检索的关键字查询业务☑️ D. Spark Streaming 主要用于实时数据的业务场景☑️</p></li><li><p>某电信部门有 100 亿条用户过往使用通讯记录，现需要提供客户终端根据电话号精 确查询历史通讯，满足用户同时并发访问，则该表应该设计为 A. Hyperbase 表+全局索引☑️ B. Hyperbase 表+es 索引 C. Es 表+es 索引 D. 以上方式都可以</p></li><li><p>可以安装 TDH 的操作系统有？ A. SUSE SP2-SP3。☑️ B. Win7/Win10。 C. CentOS 6.3-6.5。☑️ D. REHL 6.3-6.5。☑️</p></li></ol><h3 id="练习题库三">练习题库(三)</h3><ol type="1"><li><p>下列与 HDFS 有关的说法正确的是 A. HDFS DataNode 节点上的磁盘需要做 RAID1，用来保证数据的可靠性 B. HDFS 可以在磁盘之间通过 balance 操作，平衡磁盘之间的负载情况 C. HDFS 建议 DataNode 之间的数据盘个数. 容量大小不一致，以体现 HDFS 的负载 均衡能力 D. 规划 HDFS 集群时，建议 Active NameNode 和 Standby NameNode 分配在不同的 机架上☑️</p></li><li><p>NameNode 用于存储 HDFS 上数据块的元数据信息，它保存的数据形式是 A. block B. fsimage☑️ C. editlog☑️ D. blockid</p></li><li><p>在集群中配置 HDFS 的副本数为 3，设置数据块大小为 128M，此时我们上传一份 64M 的数据文件，该数据文件占用 HDFS 空间大小为 A. 64M B. 128M C. 384M☑️ D. 192M</p></li><li><p>下列对 YARN 角色在集群中的作用描述正确的是 A. 集群资源管理☑️ B. 集群任务调度与管理☑️ C. 存储部分 HDFS 上的数据块 D. 以上都正确</p></li><li><p>YARN 框架中，负责集群资源管理的组件是 A. ResourceManager☑️ B. NodeManager C. Container D. JobTracker</p></li><li><p>MapReduce 计算框架的特点包括 A. 自动化并行和分布式计算 B. 出错容忍度高 C. 优先数据本地化计算 D. 以上都是☑️</p></li><li><p>以下关于外表和托管表描述正确的是 A. 外表的数据存储在本地，托管表的数据存储在 hdfs 上 B. 删除托管表只会删除 Inceptor 上的元数据不会删除数据文件，删除外表两者都会 被删除 C. 删除外表只会删除 Inceptor 上的元数据不会删除数据文件，删除托管表两者都会 被删除☑️ D. 删除托管表或外表，incepotr 上的元数据和数据文件都会被删除</p></li><li><p>以下关于 Inceptor 数据倾斜场景正确的处理方式有 A. 对于数据倾斜的 SQL 重新跑一次即可解决 B. 剔除引起数据倾斜的数据，再重新执行 SQL C. 导入数据期间格式转换出现错误引起 null 过多，可以通过重新清理数据解决☑️ D. 将一起数据倾斜的数据和剩下的数据单独运行，再通过 union 合并的方式解决☑️</p></li><li><p>以下关于 inceptor 日志信息描述正确的有 A. Inceptor server 日志存放于各节点的/var/log/inceptorsql[x]/hive-server.log☑️ B. 可以通过 inceptor server 4040 查看 SQL 错误日志☑️ C. Excutor 日志存放于 excutor 节点的/var/log/inceptorsql[x]/spark-excutor.log☑️ D. ExcutorGC 日志存放于 excutor 节点的/var/log/inceptorsql[x]/spark-excutor.gc.log☑️</p></li><li><p>假设使用场景中有如下查询语句 <figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> Sex, Region, <span class="keyword">COUNT</span>(<span class="keyword">ID</span>), <span class="keyword">AVG</span> (Salary)</span><br><span class="line"><span class="keyword">FROM</span> Employee</span><br><span class="line"><span class="keyword">WHERE</span> Department = <span class="string">&#x27;IT&#x27;</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> Sex, Region</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> Sex, Region;</span><br></pre></td></tr></table></figure> 通过 holodesk 的 cube 和 index 手段对这种过滤率和聚合率高的业务进行优化，以下建表 正确的是 <figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">A. ☑️<span class="keyword">CREATE</span> <span class="keyword">TABLE</span> Employee</span><br><span class="line">TBLPROPERTIES (</span><br><span class="line"><span class="string">&#x27;cache&#x27;</span> = <span class="string">&#x27;RAM&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.index&#x27;</span> = <span class="string">&#x27;Department&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.dimension&#x27;</span> = <span class="string">&#x27;Sex, Region&#x27;</span>)</span><br><span class="line"></span><br><span class="line">B. <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> Employee</span><br><span class="line">TBLPROPERTIES (</span><br><span class="line"><span class="string">&#x27;cache&#x27;</span> = <span class="string">&#x27;RAM&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.index&#x27;</span> = <span class="string">&#x27;Sex, Region&#x27;</span></span><br><span class="line"><span class="string">&#x27;holodesk.dimension&#x27;</span> = <span class="string">&#x27;Department&#x27;</span> )</span><br><span class="line"></span><br><span class="line">C. <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> Employee TBLPROPERTIES (</span><br><span class="line"><span class="string">&#x27;cache&#x27;</span> = <span class="string">&#x27;Department&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.index&#x27;</span> = <span class="string">&#x27;Department&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.dimension&#x27;</span> = <span class="string">&#x27;Sex, Region&#x27;</span>)</span><br><span class="line"></span><br><span class="line">D. <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> Employee TBLPROPERTIES (</span><br><span class="line"><span class="string">&#x27;cache&#x27;</span> = <span class="string">&#x27;RAM&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.index&#x27;</span> = <span class="string">&#x27;Department&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;holodesk.dimension&#x27;</span> = <span class="string">&#x27;Sex&#x27;</span> )</span><br></pre></td></tr></table></figure></p></li><li><p>以下属于 HMaster 功能的是 A. 为 Region Server 分配 region☑️ B. 存储数据元信息 C. 对 region 进行 compact 操作 D. 管理用户对 table 的增删改查操作☑️</p></li><li><p>有关 Minor Compact 的描述正确的是 A. 一个 store 下的所有文件合并 B. 删除过期版本数据 C. 删除 delete marker 数据 D. 把多个 HFile 合成一个☑️</p></li><li><p>下列创建全局索引的语句，正确的是 <figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">A. add_index &#x27;t1&#x27;, &#x27;index_name&#x27;,&#x27;COMBINE_INDEX|INDEXED=f1:q1:9|rowKey:rowKey:10,<span class="keyword">UPDATE</span>=<span class="literal">true</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">B. add_global_index &#x27;</span>t1<span class="string">&#x27;, &#x27;</span>index_name<span class="string">&#x27;,&#x27;</span>COMBINE_INDEX|INDEXED=f1:q1:<span class="number">9</span>|rowKey:rowKey:<span class="number">10</span>,<span class="keyword">UPDATE</span>=<span class="literal">true</span><span class="string">&#x27;☑️</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">C. add_fulltext_index &#x27;</span>t1<span class="string">&#x27;, &#x27;</span>index_name<span class="string">&#x27;,&#x27;</span>COMBINE_INDEX|INDEXED=f1:q1:<span class="number">9</span>|rowKey:rowKey:<span class="number">10</span>,<span class="keyword">UPDATE</span>=<span class="literal">true</span><span class="string">&#x27;;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">D. create_global_index &#x27;</span>t1<span class="string">&#x27;, &#x27;</span>index_name<span class="string">&#x27;,&#x27;</span>COMBINE_INDEX|INDEXED=f1:q1:<span class="number">9</span>|rowKey:rowKey:<span class="number">10</span>,<span class="keyword">UPDATE</span>=<span class="literal">true</span><span class="string">&#x27;</span></span><br></pre></td></tr></table></figure></p></li><li><p>以下对流处理计算框架描述不正确的是 A. Spark Streaming 是基于微批（batch）对数据进行处理的 B. Apache Storm 是基于时间（event）对数据进行处理的 C. Transwarp StreamSQL 可基于微批或事件对数据进行处理 D. 以上说法都不对☑️</p></li><li><p>某交通部门通过使用流监控全市过往 24 小时各个卡口数据，要求每分钟更新一次， 原始流为 org_stream，以下实现正确的是 <figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">A. <span class="keyword">CREATE</span> STREAMWINDOW traffic_stream <span class="keyword">AS</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> original_stream</span><br><span class="line">STREAM w1 <span class="keyword">AS</span> (<span class="keyword">length</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">minute</span> slide <span class="string">&#x27;24&#x27;</span> <span class="keyword">hour</span>);</span><br><span class="line"></span><br><span class="line">B. <span class="keyword">CREATE</span> STREAM traffic_stream <span class="keyword">AS</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> original_stream</span><br><span class="line">STREAMWINDOW w1 <span class="keyword">AS</span> (<span class="keyword">length</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">minute</span> slide <span class="string">&#x27;24&#x27;</span> <span class="keyword">hour</span>);</span><br><span class="line"></span><br><span class="line">C. ☑️<span class="keyword">CREATE</span> STREAM traffic_stream <span class="keyword">AS</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> original_stream</span><br><span class="line">STREAMWINDOW w1 <span class="keyword">AS</span> (<span class="keyword">length</span> <span class="string">&#x27;24&#x27;</span> <span class="keyword">hour</span> slide <span class="string">&#x27;1&#x27;</span> <span class="keyword">minute</span>);</span><br><span class="line"></span><br><span class="line">D. <span class="keyword">CREATE</span> STREAM traffic_stream <span class="keyword">AS</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> original_stream <span class="keyword">AS</span> (<span class="keyword">length</span> <span class="string">&#x27;24&#x27;</span></span><br><span class="line"><span class="keyword">second</span> slide <span class="string">&#x27;1&#x27;</span> <span class="keyword">minute</span>);</span><br></pre></td></tr></table></figure></p></li><li><p>以下不是 Zookeeper 的功能是 A. 配置管理 B. 集群管理 C. 分布式锁 D. 存储大量数据☑️</p></li><li><p>关于 Hue 对 hive server 的支持度描述正确的是 A. 只支持 hive server1 B. 只支持 hive server2☑️ C. 同时支持 hive server1 和 hive server2 D. 只支持开启 LDAP 的 hive server2</p></li><li><p>以下关于 oozie 三个编辑器说法正确的是 A. bundle 构建在 workflow 工作方式之上，提供定时运行和触发运行任务的功能。 B. bundle 将多个 workflow 管理起来，这样我们只需提供一个 bundle 提交即可 C. workflow 是最简单的一种工作方式☑️ D. coordinator 可以包含一到多个 workflow☑️</p></li><li><p>有关使用 sqoop 抽取数据的原理的描述不正确的是 A. sqoop 在抽取数据的时候可以指定 map 的个数，map 的个数决定在 hdfs 生成的 数据文件的个数 B. sqoop 抽取数据是个多节点并行抽取的过程，因此 map 的个数设置的越多性能 越好☑️ C. sqoop 任务的切分是根据 split 字段的（最大值-最小值）/map 数 D. sqoop 抽取数据的时候需要保证执行当前用户有权限执行相应的操作</p></li><li><p>下面与 sqoop 做数据迁移有关的描述不正确的是 A. sqoop 做数据迁移的主要瓶颈在网络带宽和 RDB 的 IO 限制 B. sqoop 抽取数据是个多节点并行抽取的过程，因此 map 的个数设置的越多性能越 好☑️ C. sqoop 抽取数据分为全量抽取和增量抽取两种 D. 当-m 大于 1 时，就必须要设置--split-by 字段</p></li><li><p>下列有关 flume 的描述不正确的是 A. flume 是 Apache 的一个子项目 B. flume 主要是一个日志采集，传输系统 C. flume 和 sqoop 功能相似，因此可以相互替代☑️ D. flume 可以同时采集集群内部和集群外部的日志数据</p></li><li><p>下列是关于 flume 和 sqoop 对比的描述，不正确的是 A. flume 主要用来采集日志而 sqoop 主要用来做数据迁移 B. flume 主要采集流式数据而 sqoop 主要用来迁移规范化数据 C. flume 和 sqoop 都是分布式处理任务☑️ D. flume 主要用于采集多数据源小数据而 sqoop 用来迁移单数据源数据</p></li><li><p>以下对 ElasticSearch 描述不正确的是 A. ElasticSearch 是分布式全文搜索引擎 B. ElasticSearch 集群中分 master 和 data 节点 C. ElasticSearch 数据存储在 HDFS 上☑️ D. ElasticSearch 数据可以按 Shard 分布在不同的节点上</p></li><li><p>下列不属于 kafka 应用场景的是 A. 常规的消息收集 B. 网站活动性跟踪 C. 日志收集 D. 关系型数据库和大数据平台之间的数据迁移☑️</p></li><li><p>TDH 提供哪几种认证模式？ A. 所有服务使用简单认证模式——所有服务都无需认证即可互相访问☑️ B. 所有服务都启用 Kerberos 认证，用户要提供 Kerberos principal 和密码（或者 keytab）来访问各个服务☑️ C. 所有服务都启用 Kerberos 同时 Inceptor 启用 LDAP 认证☑️ D. 所有服务都启用 LDAP 认证</p></li><li><p>以下属于 Guardian 的功能是 A. 用户管理☑️ B. 用户认证☑️ C. 审计☑️ D. 权限管理☑️</p></li><li><p>Inceptor server 服务无法启动时，该如何查看日志是 A. 查看 TDH manager 所在节点/var/log/inceptorsql<em>/目录下的 hive-server2.log 日志 B. 查看 Inceptor server 所在节点/var/log/inceptorsql</em>/目录下的 hive-server2.log 日志☑️ C. 查 看 Resource Manager 所 在 节 点 /var/log/Yarn<em>/ 目 录 下 的 yarn-yarn-resourcemanager-poc-node1.log 日志 D. 查看任意节点/var/log/inceptorsql</em>/目录下的 hive-server2.log 日志</p></li><li><p>以下对 Hadoop 组件的应用场景描述正确的是 A. Hive 主要用于构建大数据数仓，主要做批处理. 统计分析型业务☑️ B. Hbase 主要用于检索查询的 OLTP 业务☑️ C. ElasticSearch 主要用于全文检索的关键字查询业务☑️ D. Spark Streaming 主要用于实时数据的业务场景☑️</p></li><li><p>现有一个表数据要存储在 hyperbase 上，并创建全文索引，原表数据 10GB，HDFS 配置为 3 副本，hyperbase 压缩比例按 1:3 计算，索引数据量为 20GB，ES 副本数为 1， ES 压缩比按 1:3 计算，则该表需要多大的存储空间存储 A. 16.67GB B. 23.33GB☑️ C. 30GB D. 70GB</p></li><li><p>下面哪些工作不属于集群预安装工作 A. 为集群中每个节点的安装操作系统 B. 选一个节点作为管理节点，修改其/etc/hosts 文件 C. 安装 Transwarp Manager 管理界面 D. 配置集群安全模式☑️</p></li></ol><h3 id="练习题库四">练习题库(四)</h3><ol type="1"><li><p>下列与 HDFS 有关的说法正确的是 A. HDFS DataNode 节点上的磁盘需要做 RAID1，用来保证数据的可靠性 B. HDFS 可以在磁盘之间通过 balance 操作，平衡磁盘之间的负载情况 C. HDFS 建议 DataNode 之间的数据盘个数. 容量大小不一致，以体现 HDFS 的负载 均衡能力 D. 规划 HDFS 集群时，建议 Active NameNode 和 Standby NameNode 分配在不同的 机架上☑️</p></li><li><p>以下哪个服务作为 HDFS 高可靠协调服务的共享存储？ A. ZooKeeper B. JournalNodes☑️ C. NameNode D. ZKFailoverController</p></li><li><p>在集群中配置 HDFS 的副本数为 3，设置数据块大小为 128M，此时我们上传一份 64M 的数据文件，该数据文件占用 HDFS 空间大小为 A. 64M B. 128M C. 384M☑️ D. 192M</p></li><li><p>在 Yarn 服务中，不包含以下哪种角色 A. ResourceManager B. NodeManager C. ApplicationMaster D. Contianer☑️</p></li><li><p>ResourceManager 是 YARN 的主要组成部分，有关其功能描述不正确的是 A. 它直接将集群所拥有的资源按需分配给运行在 YARN 上的应用程序☑️ B. 它负责将集群中的所有资源进行统一管理和分配 C. 它接受各个节点的资源汇报信息 D. 它把资源按照策略分配给各应用</p></li><li><p>当前用户提交了一个 wordcount 词频统计的任务，最后任务执行失败，可能的原因有 哪些 A. 当前集群中没有足够的资源，不足以满足当前 wordcount 任务的需求 B. 执行该任务的用户没有权限访问 HDFS 上的数据文件 C. 用户在执行任务之前在 HDFS 相应的目录下创建了提交任务时指定的输出目录 D. 以上原因都有可能☑️</p></li><li><p>以下关于外表和托管表描述正确的是 A. 外表的数据存储在本地，托管表的数据存储在 hdfs 上 B. 删除托管表只会删除 Inceptor 上的元数据不会删除数据文件，删除外表两者都会 被删除 C. 删除外表只会删除 Inceptor 上的元数据不会删除数据文件，删除托管表两者都会 被删除☑️ D. 删除托管表或外表，incepotr 上的元数据和数据文件都会被删除</p></li><li><p>SQL 运行中如果出现 maptask 数据特别多，执行时间又很短时可以通过小文件合并来 进行优化，以下是合并参数有 A. SET ngmr.partition.automerge = TRUE;☑️ B. SET ngmr.partition.mergesize = n;☑️ C. SET ngmr.partition.mergesize.mb = m;☑️ D. SET mapred.reduce.tasks = N;</p></li><li><p>以下关于 inceptor 日志信息描述正确的有 A. Inceptor server 日志存放于各节点的/var/log/inceptorsql[x]/hive-server.log☑️ B. 可以通过 inceptor server 4040 查看 SQL 错误日志☑️ C. Excutor 日志存放于 excutor 节点的/var/log/inceptorsql[x]/spark-excutor.log☑️ D. ExcutorGC 日志存放于 excutor 节点的/var/log/inceptorsql[x]/spark-excutor.gc.log☑️</p></li><li><p>tableA 有 10G 的数据，tableB 有 100G 的数据，两个表通过共有的 id 列做关联查询 name 列，以下方式可以优化计算效率的是 A. select /<em>+MAPJOIN(a)</em>/ a.name,b.name from tableA a join tableB b on a.id=b.id B. select /<em>+MAPJOIN(b)</em>/ a.name,b.name from tableA a join tableB b on a.id=b.id C. 建表时将 tableA 和 tableB 根据 id 字段分相同数量的桶☑️ D. 建表时将 tableA 和 tableB 根据 name 字段分相同数量的桶</p></li><li><p>以下属于 HMaster 功能的是 A. 为 Region Server 分配 region☑️ B. 存储数据元信息☑️ C. 对 region 进行 compact 操作 D. 管理用户对 table 的增删改查操作</p></li><li><p>Hyperbase 与 Inceptor 的关系，描述正确的是 A. 两者不可或缺，Inceptor 保证 Hyperbase 的服务的正常运行 B. 两者没有任何关系 C. Inceptor 可以访问 Hyperbase☑️ D. 两者相辅相成☑️</p></li><li><p>下列创建全局索引的语句，正确的是 <figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">A. add_index &#x27;t1&#x27;, &#x27;index_name&#x27;,</span><br><span class="line">&#x27;COMBINE_INDEX|INDEXED=f1:q1:9|rowKey:rowKey:10,<span class="keyword">UPDATE</span>=<span class="literal">true</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">B. ☑️add_global_index &#x27;</span>t1<span class="string">&#x27;, &#x27;</span>index_name<span class="string">&#x27;,</span></span><br><span class="line"><span class="string">&#x27;</span>COMBINE_INDEX|INDEXED=f1:q1:<span class="number">9</span>|rowKey:rowKey:<span class="number">10</span>,<span class="keyword">UPDATE</span>=<span class="literal">true</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">C. add_fulltext_index &#x27;</span>t1<span class="string">&#x27;, &#x27;</span>index_name<span class="string">&#x27;,</span></span><br><span class="line"><span class="string">&#x27;</span>COMBINE_INDEX|INDEXED=f1:q1:<span class="number">9</span>|rowKey:rowKey:<span class="number">10</span>,<span class="keyword">UPDATE</span>=<span class="literal">true</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">D. create_global_index &#x27;</span>t1<span class="string">&#x27;, &#x27;</span>index_name<span class="string">&#x27;,</span></span><br><span class="line"><span class="string">&#x27;</span>COMBINE_INDEX|INDEXED=f1:q1:<span class="number">9</span>|rowKey:rowKey:<span class="number">10</span>,<span class="keyword">UPDATE</span>=<span class="literal">true</span><span class="string">&#x27;</span></span><br></pre></td></tr></table></figure></p></li><li><p>以下对流处理计算框架描述不正确的是 A. Spark Streaming 是基于微批（batch）对数据进行处理的 B. Apache Storm 是基于时间（event）对数据进行处理的 C. Transwarp StreamSQL 可基于微批或事件对数据进行处理 D. 以上说法都不对☑️</p></li><li><p>某交通部门通过使用流监控全市过往 24 小时各个卡口数据，要求每分钟更新一次， 原始流为 org_stream，以下实现正确的是 <figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">A. <span class="keyword">CREATE</span> STREAMWINDOW traffic_stream <span class="keyword">AS</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> original_stream</span><br><span class="line">STREAM w1 <span class="keyword">AS</span> (<span class="keyword">length</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">minute</span> slide <span class="string">&#x27;24&#x27;</span> <span class="keyword">hour</span>);</span><br><span class="line"></span><br><span class="line">B. <span class="keyword">CREATE</span> STREAM traffic_stream <span class="keyword">AS</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> original_stream</span><br><span class="line">STREAMWINDOW w1 <span class="keyword">AS</span> (<span class="keyword">length</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">minute</span> slide <span class="string">&#x27;24&#x27;</span> <span class="keyword">hour</span>);</span><br><span class="line"></span><br><span class="line">C. ☑️<span class="keyword">CREATE</span> STREAM traffic_stream <span class="keyword">AS</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> original_stream</span><br><span class="line">STREAMWINDOW w1 <span class="keyword">AS</span> (<span class="keyword">length</span> <span class="string">&#x27;24&#x27;</span> <span class="keyword">hour</span> slide <span class="string">&#x27;1&#x27;</span> <span class="keyword">minute</span>);</span><br><span class="line"></span><br><span class="line">D. <span class="keyword">CREATE</span> STREAM traffic_stream <span class="keyword">AS</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> original_stream <span class="keyword">AS</span> (<span class="keyword">length</span> <span class="string">&#x27;24&#x27;</span></span><br><span class="line"><span class="keyword">second</span> slide <span class="string">&#x27;1&#x27;</span> <span class="keyword">minute</span>);</span><br></pre></td></tr></table></figure></p></li><li><p>Zookeeper 服务描述正确的为 A. Zookeeper 中每一个 server 互为 leader。 B. Zookeeper 中只有一个 leader，并通过备份机制产生。 C. Zookeeper 中不存在 leader,所有 server 共同提供服务。 D. Zookeeper 通过选举机制确定 leader，有且仅有一个。☑️</p></li><li><p>通过 Hue 修改 HDFS 目录或文件的权限可以通过以下哪些方式实现 A. Hdfs 相应的权限☑️ B. 通过 Hue 超级用户 hue 登录 C. 以 hdfs 用户登录☑️ D. 以上都可以</p></li><li><p>通过 Oozie 使用 ssh，必须满足以下条件 A. 以 root 用户登录各个节点 B. Oozie 用户可以免密钥登录☑️ C. Oozie 用户必须要有 bash 权限☑️ D. 所访问必须是集群的节点</p></li><li><p>有关使用 sqoop 抽取数据的原理的描述不正确的是 A. sqoop 在抽取数据的时候可以指定 map 的个数，map 的个数决定在 hdfs 生成的 数据文件的个数 B. sqoop 抽取数据是个多节点并行抽取的过程，因此 map 的个数设置的越多性能 越好☑️ C. sqoop 任务的切分是根据 split 字段的（最大值-最小值）/map 数 D. sqoop 抽取数据的时候需要保证执行当前用户有权限执行相应的操作</p></li><li><p>在使用 sqoop 连接关系型数据时，下面哪个命令可以查看关系型数据库中有哪些表？ <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A. sqoop list-databases</span><br><span class="line">--username root</span><br><span class="line">--password 111111</span><br><span class="line">--connect jdbc:mysql:&#x2F;&#x2F;192.168.164.25:3306&#x2F;</span><br><span class="line"></span><br><span class="line">B. sqoop list-databases</span><br><span class="line">--username root</span><br><span class="line">-P</span><br><span class="line">--connect jdbc:mysql:&#x2F;&#x2F;192.168.164.25:3306&#x2F;</span><br><span class="line"></span><br><span class="line">C. sqoop list-databases</span><br><span class="line">--username root</span><br><span class="line">--password-file file:&#x2F;root&#x2F;.pwd</span><br><span class="line">--connect jdbc:mysql:&#x2F;&#x2F;192.168.164.25:3306&#x2F;</span><br><span class="line"></span><br><span class="line">D. ☑️sqoop list-tables</span><br><span class="line">--username root</span><br><span class="line">--password 111111</span><br><span class="line">--connect jdbc:mysql:&#x2F;&#x2F;192.168.164.25:3306&#x2F;test</span><br></pre></td></tr></table></figure></p></li><li><p>要将采集的日志数据作为 kafka 的数据源，则 flume sink 需要设置为下列哪项参数 A. hdfs B. kafka C. org.apache.flume.sink.kafka.KafkaSink☑️ D. {topicname}</p></li><li><p>下列是关于 flume 和 sqoop 对比的描述，不正确的是 A. flume 主要用来采集日志而 sqoop 主要用来做数据迁移 B. flume 主要采集流式数据而 sqoop 主要用来迁移规范化数据 C. flume 和 sqoop 都是分布式处理任务☑️ D. flume 主要用于采集多数据源小数据而 sqoop 用来迁移单数据源数据</p></li><li><p>有关 Elasticsearch 描述有误的一项是 A. 它会利用多播形式发现节点。 B. 主节点(master node) 通过选举方式产生。 C. 主节点(master node)进行集群的管理，只负责集群节点添加和删除。☑️ D. 主节点会去读集群状态信息，必要的时候进行恢复工作。</p></li><li><p>下面措施中，不能保证 kafka 数据可靠性的是 A. kafka 会将所有消息持久化到硬盘中保证其数据可靠性 B. kafka 通过 Topic Partition 设置 Replication 来保证其数据可靠性 C. kafka 通过设置消息重发机制保证其数据可靠性 D. kafka 无法保证数据可靠性☑️</p></li><li><p>TDH 提供哪几种认证模式？ A. 所有服务使用简单认证模式——所有服务都无需认证即可互相访问☑️ B. 所有服务都启用 Kerberos 认证，用户要提供 Kerberos principal 和密码（或者keytab）来访问各个服务☑️ C. 所有服务都启用 Kerberos 同时 Inceptor 启用 LDAP 认证☑️ D. 所有服务都启用 LDAP 认证</p></li><li><p>开启 LDAP 后，应该使用哪个命令连接 Inceptor A. transwarp -t -h <span class="math inline">\(ip。 B. beeline -u jdbc:hive2://\)</span>ip:10000 -n $username -p <span class="math inline">\(password。☑️ C. beeline -u &quot;jdbc:hive2://\)</span>ip:10000/default;principal=hive/node1@TDH"。 D. beeline -u "jdbc:hive2://$ip:10000/default;principal=user1@TDH"。</p></li><li><p>Inceptor server 服务无法启动时，该如何查看日志是 A. 查看 TDH manager 所在节点/var/log/inceptorsql<em>/目录下的 hive-server2.log 日志 B. 查看 Inceptor server 所在节点/var/log/inceptorsql</em>/目录下的 hive-server2.log 日志☑️ C. 查 看 Resource Manager 所 在 节 点 /var/log/Yarn<em>/ 目 录 下 的yarn-yarn-resourcemanager-poc-node1.log 日志 D. 查看任意节点/var/log/inceptorsql</em>/目录下的 hive-server2.log 日志</p></li><li><p>现有一批数据需要进行清洗，要求对其中 null 通过 update 转换为 0，删除重复的记 录，添加部分新的记录，则该表应该设计为 A. Tex 表 B. Orc 表 C. Orc 事务表☑️ D. Holodesk 表</p></li><li><p>现有一个表数据要存储在 hyperbase 上，并创建全文索引，原表数据 10GB，HDFS 配置为 3 副本，hyperbase 压缩比例按 1:3 计算，索引数据量为 20GB，ES 副本数为 1， ES 压缩比按 1:3 计算，则该表需要多大的存储空间存储 A. 16.67GB B. 23.33GB☑️ C. 30GB D. 70GB</p></li><li><p>下面哪些工作不属于集群预安装工作 A. 为集群中每个节点的安装操作系统 B. 选一个节点作为管理节点，修改其 /etc/hosts 文件 C. 安装 Transwarp Manager 管理界面 D. 配置集群安全模式☑️</p></li></ol><h3 id="问答题">问答题</h3><ol type="1"><li>集群有 8 个节点，每个节点有 8 块硬盘（默认 3 副本）。如果某个节点有 3 块盘损坏，是否可能存在数据块丢失情况；如果有 3 个节点发生故障，是否可能存在数据块丢失情况；并简述原因。</li><li>请描述 TDH 平台中在 Yarn 上可以使用哪几种调度策略，并分别阐述各调度策略的特点。 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FIFO Scheduler（先进先出调度器）：(策略)将所有任务放入一个队列，先进队列的先获得资源，排在后面的任务只有等待。(缺点)－资源利用率低，无法交叉运行任务。－灵活性差。</span><br><span class="line"></span><br><span class="line">Capacity Scheduler（容量调度器）：(思想)提前做预算，在预算指导下分享集群资源。(策略)集群资源由多个队列分享。每个队列都要预设资源分配的比例（提前做预算）。空闲资源优先分配给“实际资源&#x2F;预算资源”比值最低的队列。队列内部采用FIFO调度策略。(特点)层次化的队列设计。容量保证：每个队列都要预设资源占比，防止资源独占。弹性分配：空闲资源可以分配给任何队列，当多个队列争用时，会按比例进行平衡。支持动态管理。访问控制。多租户：多用户共享集群资源。</span><br><span class="line"></span><br><span class="line">Fair Scheduler（公平调度器）：（调度策略)多队列公平共享集群资源。通过平分的方式，动态分配资源，无需预先设定资源分配比例。队列内部可配置调度策略：FIFO、Fair（默认）。</span><br></pre></td></tr></table></figure></li><li>请描述一个 100GB 文件写入 HDFS 的整个过程（使用 bulkload 方式实现） <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">抽取：从数据源中抽取数据</span><br><span class="line">对于MySQL，运行mysqldump命令导出数据</span><br><span class="line"></span><br><span class="line">转换：利用MapReduce，将数据转换为HFile文件</span><br><span class="line">对于TSV或CSV文件，使用HBase ImportTsv工具将其转换成HFile文件 －每个输出文件夹中的每个区域都会创建一个HFile文件</span><br><span class="line"></span><br><span class="line">加载：将HFile文件加载到HBase</span><br><span class="line">利用HBase CompleteBulkLoad工具，将HFile文件移动到HBase表的相应目录中，完成加载</span><br><span class="line"></span><br><span class="line">具体来说：</span><br><span class="line">1)客户端发送创建文件指令给分布式文件系统</span><br><span class="line">2)文件系统告知namenode (检查权限，查看文件是否存在。EditLog增加记录。返回输出流对象)</span><br><span class="line">3)客户端往输出流中写入数据,分成一个个数据包</span><br><span class="line">4)根据namenode分配,输出流往datanode写数据(多个datanode构成一个管道pipeline,输出流写第一个,后面的转发)</span><br><span class="line">4)每个datanode写完一个块后，返回确认信息</span><br><span class="line">5)写完数据，关闭输出流</span><br><span class="line">6)发送完成信号给namenode</span><br></pre></td></tr></table></figure></li><li>请以 WordCount 为例描述 MapReduce 的运行过程，并列出 Spark 相较 MapReduce 的 优势 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">过程：todo</span><br><span class="line"></span><br><span class="line">优势：基于内存计算RDD;基于DAG优化任务流程(延迟计算);易于部署,更低的框架开销;丰富的API支持。</span><br></pre></td></tr></table></figure></li><li>写出以下场景下的优化思路</li></ol><ol type="a"><li>假设在 Inceptor 上执行任务，发现 Map Task 数量多、执行时间短，应采取哪种措施来提升性能？ <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">对数据块进行合并：Automerge（碎片自动合并）</span><br></pre></td></tr></table></figure></li><li>请简述在 Inceptor 中大表与大表做 join、大表与小表做 join 时分别有哪些优化手段 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">大表与大表的普通JOIN：实现普通JOIN的过程是这样的：扫描过滤两张表的数据（Map Stages），然后通过Shuffle将Key哈希值相同的数据分发到各个节点，在各节点内部执行JOIN（Reduce Stages）</span><br><span class="line"></span><br><span class="line">MapJoin是一种针对大表与小表JOIN的特殊实现方式，在大小表数据量悬殊的情况下能有效的提升JOIN执行效率，一般受优化开关或者Hint控制启动。</span><br></pre></td></tr></table></figure></li></ol><ol start="6" type="1"><li>请列出 TDH 下的 4 大组件（Inceptor、Hyperbase、StreamSQL、Discover）的特性以及适用场景。</li><li>假设集群的每个节点初始有 6 块硬盘，运行一段时间后，每个节点又加了 4 块新硬盘， 为了使数据在所有硬盘上分布均匀，能否通过 hdfs balancer 达到效果，为什么？并列出能达到效果的两种措施。 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">不能，旧版本的hdfs仅支持节点间的数据平衡，新版本可通过balancer实现</span><br><span class="line">1.手动重写所有数据  2.将数据全部移到几个节点上，再在节点间数据平衡</span><br></pre></td></tr></table></figure></li><li>请描述高并发检索和综合搜索的场景特点，这两种场景应使用哪种技术来做支撑， 并指出数据和索引各自的存储位置。</li><li>请描述 HDFS 的高可用性实现机制</li><li>请列举出平台支持的 5 种存储格式/引擎的表，并详细描述各自的存储特点、使用场景、支持的操作以及是否支持分区分桶 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Text 表：</span><br><span class="line">ORC 表：</span><br><span class="line">事务表：</span><br><span class="line">HoloDesk 表：</span><br><span class="line">Hyperbase 表：</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      星环考试问答
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>[课堂笔记] 高级软件设计</title>
    <link href="https://wym0120.github.io/2020/11/12/lecture/software-design/SD-notes/"/>
    <id>https://wym0120.github.io/2020/11/12/lecture/software-design/SD-notes/</id>
    <published>2020-11-12T06:33:15.000Z</published>
    <updated>2021-04-12T15:01:26.107Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本概念">基本概念</h2><ol type="1"><li><p>设计模式的定义 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">在软件工程中，设计模式是一种在特定上下文中应对反复出现的问题的可重用的通用的解决方案</span><br></pre></td></tr></table></figure></p></li><li><p>设计模式的分类 <img src="https://mignuw-private-blog.oss-cn-shanghai.aliyuncs.com/img/20201209212805.png" /></p></li></ol><h2 id="模式类图">模式类图</h2><h3 id="策略模式">策略模式</h3><p><img src="https://mignuw-private-blog.oss-cn-shanghai.aliyuncs.com/img/20201209215200.png" /> ### 状态模式 <img src="https://mignuw-private-blog.oss-cn-shanghai.aliyuncs.com/img/20201209215132.png" /> ### 观察者模式 <img src="https://mignuw-private-blog.oss-cn-shanghai.aliyuncs.com/img/20201209215105.png" /> ### 装饰者模式 <img src="https://mignuw-private-blog.oss-cn-shanghai.aliyuncs.com/img/20201209215537.png" /> ### 工厂方法模式 <img src="https://mignuw-private-blog.oss-cn-shanghai.aliyuncs.com/img/20201209215328.png" /> ### 抽象工厂模式 <img src="https://mignuw-private-blog.oss-cn-shanghai.aliyuncs.com/img/20201209215302.png" /> ### 命令模式 <img src="https://mignuw-private-blog.oss-cn-shanghai.aliyuncs.com/img/20201209215002.png" /> ### 适配器模式 <img src="https://mignuw-private-blog.oss-cn-shanghai.aliyuncs.com/img/20201209215450.png" /> ### 外观模式 <img src="https://mignuw-private-blog.oss-cn-shanghai.aliyuncs.com/img/20201209215602.png" /> ### 模版模式 <img src="https://mignuw-private-blog.oss-cn-shanghai.aliyuncs.com/img/20201209215225.png" /> ### 迭代器模式 <img src="https://mignuw-private-blog.oss-cn-shanghai.aliyuncs.com/img/20201209215659.png" /> ### 组合模式 <img src="https://mignuw-private-blog.oss-cn-shanghai.aliyuncs.com/img/20201209215511.png" /> ### 单例模式 <img src="https://mignuw-private-blog.oss-cn-shanghai.aliyuncs.com/img/20201209215353.png" /> ### 代理模式 <img src="https://mignuw-private-blog.oss-cn-shanghai.aliyuncs.com/img/20201209215633.png" /></p><h2 id="题目">题目</h2><h3 id="模式体现什么设计原则">模式体现什么设计原则</h3><h3 id="意图汇总">意图汇总</h3><table><thead><tr class="header"><th>模式</th><th>意图</th></tr></thead><tbody><tr class="odd"><td>策略</td><td>定义一系列算法，封装每个算法，并使它们可互换。策略允许算法独立于使用它的客户机而变化。</td></tr><tr class="even"><td>状态</td><td>允许对象在内部状态发生改变时改变它的行为</td></tr><tr class="odd"><td>观察者</td><td>定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新</td></tr><tr class="even"><td>装饰者</td><td>允许向一个现有的对象添加新的功能，同时又不改变其结构</td></tr><tr class="odd"><td>工厂</td><td>定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类，工厂模式使其创建过程延迟到子类进行</td></tr><tr class="even"><td>抽象工厂</td><td>提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类</td></tr><tr class="odd"><td>命令</td><td>将一个请求封装成一个对象，从而使您可以用不同的请求对客户进行参数化</td></tr><tr class="even"><td>适配器</td><td>将一个类的接口转换成客户希望的另外一个接口</td></tr><tr class="odd"><td>外观</td><td>为高层模块提供一个一致的接口访问多个复杂的子系统</td></tr><tr class="even"><td>模版</td><td>定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤</td></tr><tr class="odd"><td>迭代器</td><td>提供一种方法顺序访问一个聚合对象中各个元素, 而又无须暴露该对象的内部表示</td></tr><tr class="even"><td>组合</td><td>将对象组合成树形结构以表示"部分-整体"的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性</td></tr><tr class="odd"><td>单例</td><td>保证一个类仅有一个实例，并提供一个访问它的全局访问点</td></tr><tr class="even"><td>代理</td><td>为其他对象提供一种代理以控制对这个对象的访问</td></tr></tbody></table><hr /><h3 id="设计原则">设计原则</h3><h4 id="principles">Principles</h4><ol type="1"><li>Encapsulate what varies.</li><li>Favor composition over inheritance.</li><li>Program to interfaces, not implementations.</li><li>Strive for loosely coupled designs between objects that interact.</li><li>The Open-Closed Principle ：Classes should be open for extension, but closed for modification</li><li>Dependency Inversion Principle ：Depend upon abstractions. Do not depend upon concrete classes.</li><li>The Hollywood Principle ：Don’t call me, we’ll call you</li><li>Single Responsibility ：A class should have only one reason to change</li><li>Principle of Least Knowledge ：talk only to your immediate friends</li></ol><p>⚠️以下分类不一定完全正确仅代表个人观点 <img src="https://mignuw-private-blog.oss-cn-shanghai.aliyuncs.com/img/20201209232932.png" /></p><h4 id="思考题">思考题</h4><ol type="1"><li>好莱坞原则与依赖倒置的关系 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">依赖倒置原则强调尽可能避免使用具体类，而多使用抽象。而好莱坞原则是让低层组件能够被 hook 进计算并且高层不依赖低层。两者的目的都是结偶，但是依赖倒置更加注重如何在设计中避免依赖</span><br></pre></td></tr></table></figure></li><li>好莱坞原则中低层组建不可以调用高层组建中的方法吗？ <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">不完全是，低层会调用高层中继承来的方法。好莱坞原则要避免的是高层和低层之间的环形依赖</span><br></pre></td></tr></table></figure></li><li>透明的组合模式和安全的组合模式之间的tradeoff <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">透明的组合模式：客户不去了解具体实现，采用一致处理，牺牲安全性</span><br><span class="line">安全的组合模式：先判断再处理，牺牲透明性</span><br></pre></td></tr></table></figure></li></ol><hr /><h3 id="不同模式之间的比较">不同模式之间的比较</h3><ol type="1"><li>比较策略模式和状态模式 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 策略模式是定义一个算法家族，把他们封装起来，使得他们之间可以相互替换</span><br><span class="line">- 状态模式是将一个个状态封装成一个个类，当内部状态发生改变时，改变他们的行为</span><br><span class="line">- 策略模式和状态模式的类图几乎一样，策略模式中，客户端知道具体的策略有哪些，客户端能够通过setStrategy方法来动态的设置具体使用哪个策略，状态模式中，客户端不知道内部状态是怎么变化的，状态模式通过状态转移来组合State对象，最后把行为呈现出来</span><br></pre></td></tr></table></figure></li><li>比较策略模式和模版方法模式 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 策略模式和模版方法模式的共同点是都封装算法</span><br><span class="line">- 策略模式是定义算法家族，让他们之间可以相互替换，模版方法是针对一个算法流程，某个步骤的具体细节交给子类去实现。策略模式可以改变算法流程，使一个个步骤可以相互替换，模版方法模式算法流程是固定的</span><br><span class="line">- 策略模式使用组合来实现，模版方法模式使用继承来实现</span><br></pre></td></tr></table></figure></li><li>比较适配器模式、外观模式、装饰者模式的意图 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 适配器模式是把一个类的接口转换成客户期望的接口，让原本接口不兼容的类兼容，适配器模式一般用于想要复用某个类的场景；外观模式是封装子系统，提供简单的子系统的入口，同时简化层间调用</span><br><span class="line">- 装饰者模式是动态的给被装饰者添加职责，主要目的是扩展功能</span><br><span class="line">- 对于装饰者和适配器，他们都属于包装模式，装饰者需要满足is-a关系，不管如何包装，都有共同的父类，而适配器主要解决兼容问题，不一定要统一父类</span><br></pre></td></tr></table></figure></li><li>比较模版方法模式和工厂模式 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">工厂模式是模版方法的特殊实现，工厂里面的创建对象，就相当于只有一个步骤的模版方法模式，这个步骤交给子类去实现</span><br></pre></td></tr></table></figure></li><li>比较装饰者模式和静态代理模式 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 装饰者模式是动态的给组件对象添加“职责”，更多的考虑功能的扩展，而代理模式控制对象</span><br><span class="line">的访问，也能做方法的增强</span><br><span class="line">- 装饰者模式中，客户端可以看到具体的装饰有哪些，而代理模式把对象的具体信息给隐藏了</span><br><span class="line">起来</span><br><span class="line">- 装饰者模式是把原始组件对象传入构造器中，代理模式是创建一个对象的实例</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      软件设计课堂笔记 &amp; 复习
    
    </summary>
    
    
      <category term="Designing" scheme="https://wym0120.github.io/categories/Designing/"/>
    
    
      <category term="lecture notes" scheme="https://wym0120.github.io/tags/lecture-notes/"/>
    
  </entry>
  
  <entry>
    <title>[MIT Lecture] How to Speak</title>
    <link href="https://wym0120.github.io/2020/10/21/report/MIT-how-to-speck/"/>
    <id>https://wym0120.github.io/2020/10/21/report/MIT-how-to-speck/</id>
    <published>2020-10-21T07:48:02.000Z</published>
    <updated>2021-04-12T15:01:26.111Z</updated>
    
    <content type="html"><![CDATA[<h3 id="如何开始一个talk">如何开始一个talk</h3><p>不要在一开始就使用一个玩笑作为开场: 因为大部分人在这个时候正在习惯你的用词、声音，或者正在调整笔记本电脑。而是应该使用一个Promise，告诉听众们他们会在接下一段时间中听到什么东西。</p><h3 id="一些启发式的例子">一些启发式的例子</h3><p><strong><em>cycle</em></strong>： 你应该重复三次左右去确保你的每个听众在被弄混乱的时候都能够意识到你要说的是什么，这是一个概率问题 <strong><em>build fence</em></strong>：把自己的想法包围起来以区分于其他人的想法、其它的工作，划定一个边界 <strong><em>verbal punctuation</em></strong>：划定一些里程碑/标志点一样的东西让听众可以快速的回忆起来之前的内容，从整体上面把握对talk的理解，就像一个outline一样的东西。也方便talker快速的回到某个点 <strong><em>question</em></strong>：谨慎的选择问题，一般会等待7秒钟</p><h3 id="一些演讲的选择">一些演讲的选择</h3><p>time ： 11 AM 比较合适 place ： 尽量光线充足 cased ：提前适应场地 populated ： 场地大小要合适</p><p>board - 可以方便的使用图形 - 写字的速度和思考的速度接近 - 能找到放手的位置</p><p>props - 使用一些道具来让陈述更加有趣更加具有说服力</p><blockquote><p>board 和 props 也许都能够让人更感受到所说的东西的存在，但是 ppt 做不到这个效果</p></blockquote><h3 id="ppt中的一些技巧">ppt中的一些技巧</h3><ul><li>不要只是重复阅读ppt中的文字</li><li>每个透明度应该都只有很少的词，并且这些词应该易于阅读</li><li>不要有太多的字</li><li>尽量在ppt的旁边讲述，以免听众反复转移视线</li><li>去除掉无用的杂乱的背景、logo、去掉无用的单词，甚至可以去掉title（但是需要告知听众title）</li><li>用箭头代替激光笔、指挥棒</li></ul><h3 id="如何激励听众">如何激励听众</h3><blockquote><p>talker对自己的演讲充满热情</p></blockquote><h3 id="steps-of-giving-a-job-talk-technical-talk">Steps of giving a job talk / technical talk</h3><ol type="1"><li>vision</li></ol><ul><li>probelms</li><li>approaches</li></ul><ol start="2" type="1"><li>have done something 列举出来每一步需要做什么， 一些约束，怎么才能够完成这些事情</li><li>contributions</li></ol>]]></content>
    
    <summary type="html">
    
      How To Speak by Patrick Winston
    
    </summary>
    
    
      <category term="report" scheme="https://wym0120.github.io/categories/report/"/>
    
    
  </entry>
  
  <entry>
    <title>Bridging the gap between AI and SE</title>
    <link href="https://wym0120.github.io/2020/10/19/report/school-report-1/"/>
    <id>https://wym0120.github.io/2020/10/19/report/school-report-1/</id>
    <published>2020-10-19T05:58:17.000Z</published>
    <updated>2021-04-12T15:01:26.112Z</updated>
    
    <content type="html"><![CDATA[<p>background : 大量的软件开发过程中间产品 problem : 大量的噪音和数据具有异构性 key point : 把软件过程中产生的产品逆向来造各种各样的工具 + 机器来理解人的行为 -&gt; 智能软件开发</p><p>research topics: - intelligent code assistant - code completion - clone detection - API recommenddation - stackoverflow + API doc - knowledge graphbased api misuse detection - automated answer - interactive query refinement for technical question retrieval - intelligent bug management and fixing - feature engineering for invalid bug determination - just in time defect identification and localization(data from github) - automatic document generation - code summarization - code comment updating - commit message generation - pull request generation - hunman-centric software engineering - predicting coding context - development intention and behavior</p><p>research methodology: empirical study -&gt; (intelligent tools &lt;-&gt; empirical study)</p>]]></content>
    
    <summary type="html">
    
      Bridging the gap between AI and SE
    
    </summary>
    
    
      <category term="report" scheme="https://wym0120.github.io/categories/report/"/>
    
    
  </entry>
  
  <entry>
    <title>Citrine: Providing Intelligent Copy-and-Paste</title>
    <link href="https://wym0120.github.io/2020/09/25/paper/copy-and-paste-1/"/>
    <id>https://wym0120.github.io/2020/09/25/paper/copy-and-paste-1/</id>
    <published>2020-09-25T06:27:31.000Z</published>
    <updated>2021-04-12T15:01:26.111Z</updated>
    
    <content type="html"><![CDATA[<h3 id="abstract">Abstract</h3><blockquote></blockquote><p>keywords:</p><h3 id="总体评价">总体评价</h3><h3 id="motivation">Motivation</h3><h3 id="evalution">Evalution</h3><h3 id="details">Details</h3>]]></content>
    
    <summary type="html">
    
      Citrine: Providing Intelligent Copy-and-Paste
    
    </summary>
    
    
      <category term="paper" scheme="https://wym0120.github.io/categories/paper/"/>
    
    
  </entry>
  
  <entry>
    <title>Types and Programming Languages notes</title>
    <link href="https://wym0120.github.io/2020/09/25/lecture/fspl/tpl-notes/"/>
    <id>https://wym0120.github.io/2020/09/25/lecture/fspl/tpl-notes/</id>
    <published>2020-09-25T05:59:52.000Z</published>
    <updated>2021-04-12T15:01:26.105Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ch3-untyped-arithmetic-expressions">ch3 Untyped Arithmetic Expressions</h2>]]></content>
    
    <summary type="html">
    
      Types and Programming Languages notes
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>[ISER] [SEP] Automating string processing in spreadsheets using input-output examples</title>
    <link href="https://wym0120.github.io/2020/09/18/paper/ISER/Software%20Engineering%20Process/sep-5/"/>
    <id>https://wym0120.github.io/2020/09/18/paper/ISER/Software%20Engineering%20Process/sep-5/</id>
    <published>2020-09-18T10:56:03.000Z</published>
    <updated>2021-04-12T15:01:26.109Z</updated>
    
    <content type="html"><![CDATA[<h3 id="abstract">Abstract</h3><blockquote></blockquote><p>keywords:</p><h3 id="总体评价">总体评价</h3><h3 id="motivation">Motivation</h3><h3 id="evalution">Evalution</h3><h3 id="details">Details</h3>]]></content>
    
    <summary type="html">
    
      Sumit Gulwani. Automating string processing in spreadsheets using input-output examples. POPL&#39;11
    
    </summary>
    
    
      <category term="paper" scheme="https://wym0120.github.io/categories/paper/"/>
    
    
      <category term="Software Engineering Process" scheme="https://wym0120.github.io/tags/Software-Engineering-Process/"/>
    
  </entry>
  
  <entry>
    <title>[ISER] [SEP] code2vec: Learning distributed representations of code</title>
    <link href="https://wym0120.github.io/2020/09/18/paper/ISER/Software%20Engineering%20Process/sep-4/"/>
    <id>https://wym0120.github.io/2020/09/18/paper/ISER/Software%20Engineering%20Process/sep-4/</id>
    <published>2020-09-18T10:48:08.000Z</published>
    <updated>2021-04-12T15:01:26.109Z</updated>
    
    <content type="html"><![CDATA[<h3 id="abstract">Abstract</h3><blockquote></blockquote><p>keywords:</p><h3 id="总体评价">总体评价</h3><h3 id="motivation">Motivation</h3><h3 id="evalution">Evalution</h3><h3 id="details">Details</h3>]]></content>
    
    <summary type="html">
    
      Uri Alon, Meital Zilberstein, Omer Levy, and Eran Yahav. code2vec: Learning distributed representations of code. POPL&#39;19
    
    </summary>
    
    
      <category term="paper" scheme="https://wym0120.github.io/categories/paper/"/>
    
    
      <category term="Software Engineering Process" scheme="https://wym0120.github.io/tags/Software-Engineering-Process/"/>
    
  </entry>
  
  <entry>
    <title>[ISER] [SME] Ten years of implementation and experience</title>
    <link href="https://wym0120.github.io/2020/09/18/paper/ISER/Software%20Maintenance%20and%20Evolution/sme-4/"/>
    <id>https://wym0120.github.io/2020/09/18/paper/ISER/Software%20Maintenance%20and%20Evolution/sme-4/</id>
    <published>2020-09-18T10:26:42.000Z</published>
    <updated>2021-04-12T15:01:26.110Z</updated>
    
    <content type="html"><![CDATA[<h3 id="abstract">Abstract</h3><blockquote></blockquote><p>keywords:</p><h3 id="总体评价">总体评价</h3><h3 id="motivation">Motivation</h3><h3 id="evalution">Evalution</h3><h3 id="details">Details</h3>]]></content>
    
    <summary type="html">
    
      Kirk Glerum, Kinshuman Kinshumann, Steve Greenberg, Gabriel Aul, Vince Orgovan, Greg Nichols, David Grant, Gretchen Loihle, and Galen Hunt. Debugging in the (very) large: Ten years of implementation and experience. SOSP&#39;09
    
    </summary>
    
    
      <category term="paper" scheme="https://wym0120.github.io/categories/paper/"/>
    
    
      <category term="Software Maintence and Evolution" scheme="https://wym0120.github.io/tags/Software-Maintence-and-Evolution/"/>
    
  </entry>
  
  <entry>
    <title>[ISER] [SME] A technique for cheap recovery</title>
    <link href="https://wym0120.github.io/2020/09/18/paper/ISER/Software%20Maintenance%20and%20Evolution/sme-3/"/>
    <id>https://wym0120.github.io/2020/09/18/paper/ISER/Software%20Maintenance%20and%20Evolution/sme-3/</id>
    <published>2020-09-18T10:26:39.000Z</published>
    <updated>2021-04-12T15:01:26.110Z</updated>
    
    <content type="html"><![CDATA[<h3 id="abstract">Abstract</h3><blockquote></blockquote><p>keywords:</p><h3 id="总体评价">总体评价</h3><h3 id="motivation">Motivation</h3><h3 id="evalution">Evalution</h3><h3 id="details">Details</h3>]]></content>
    
    <summary type="html">
    
      George Candea, Shinichi Kawamoto, Yuichi Fujiki, Greg Friedman, and Armando Fox. Microreboot – A technique for cheap recovery. OSDI&#39;04
    
    </summary>
    
    
      <category term="paper" scheme="https://wym0120.github.io/categories/paper/"/>
    
    
      <category term="Software Maintence and Evolution" scheme="https://wym0120.github.io/tags/Software-Maintence-and-Evolution/"/>
    
  </entry>
  
  <entry>
    <title>[ISER] [SME] Simplifying and isolating failure-inducing input</title>
    <link href="https://wym0120.github.io/2020/09/18/paper/ISER/Software%20Maintenance%20and%20Evolution/sme-2/"/>
    <id>https://wym0120.github.io/2020/09/18/paper/ISER/Software%20Maintenance%20and%20Evolution/sme-2/</id>
    <published>2020-09-18T10:26:36.000Z</published>
    <updated>2021-04-12T15:01:26.110Z</updated>
    
    <content type="html"><![CDATA[<h3 id="abstract">Abstract</h3><blockquote><p>Given some test case, a program fails. Which circumstances of the test case are responsible for the particular failure? The Delta Debugging algorithm generalizes and simplifies some failing test case to a minimal test case that still produces the failure; it also isolates the difference between a passing and a failing test case.</p></blockquote><blockquote><p>In a case study, the Mozilla web browser crashed after 95 user actions. Our prototype implementation automatically simplified the input to 3 relevant user actions. Likewise, it simplified 896 lines of HTML to the single line that caused the failure. The case study required 139 automated test runs, or 35 minutes on a 500 MHz PC.</p></blockquote><p>keywords: Terms—automated debugging, debugging aids, testing tools, combinatorial testing, diagnostics, tracing.</p><h3 id="总体评价">总体评价</h3><h3 id="motivation">Motivation</h3><p>对于开发者们来说bug report有一个固有的矛盾，他们既希望report能够special且详尽，又希望report能够集中在关键的几个语句上以便定位bug和将类似的问题聚集在一起。这篇文章希望模拟人的思考逻辑通过二分的方法来定位到bug的存在。这篇文章通过ddmin的方法来找到一个最小的能够正好触发bug的集合和一个与它几乎一致但是略微不同的且不能触发bug的集合。来帮助开发者减少debug所消耗的时间。</p><h3 id="evalution">Evalution</h3><h3 id="details">Details</h3>]]></content>
    
    <summary type="html">
    
      Andreas Zeller and Ralf Hildebrandt. Simplifying and isolating failure-inducing input. IEEE Transactions on Software Engineering (TSE), 28(2), 2002.
    
    </summary>
    
    
      <category term="paper" scheme="https://wym0120.github.io/categories/paper/"/>
    
    
      <category term="Software Maintence and Evolution" scheme="https://wym0120.github.io/tags/Software-Maintence-and-Evolution/"/>
    
  </entry>
  
  <entry>
    <title>[ISER] [SME] Visualization of test information to assist fault localization</title>
    <link href="https://wym0120.github.io/2020/09/18/paper/ISER/Software%20Maintenance%20and%20Evolution/sme-1/"/>
    <id>https://wym0120.github.io/2020/09/18/paper/ISER/Software%20Maintenance%20and%20Evolution/sme-1/</id>
    <published>2020-09-18T10:26:34.000Z</published>
    <updated>2021-04-12T15:01:26.109Z</updated>
    
    <content type="html"><![CDATA[<h3 id="abstract">Abstract</h3><blockquote><p>One of the most expensive and time-consuming components of the debugging process is locating the errors or faults. To locate faults, developers must identify statements involved in failures and select suspicious statements that might contain faults. This paper presents a new technique that uses visualization to assist with these tasks. The technique uses color to visually map the participation of each program statement in the out ome of the execution of the program with a test suite, onsisting of both passed and failed test cases. Based on this visual mapping, a user can inspe t the statements in the program, identify statements involved in failures, and locate potentially faulty statements. The paper also describes a prototype tool that implements our technique along with a set of empirical studies that use the tool for evaluation of the technique. The empirical studies show that, for the subject we studied, the technique can be eeffective in helping a user locate faults in a program.</p></blockquote><p>keywords: software visualization,fault localization,debugging,testing</p><h3 id="总体评价">总体评价</h3><h3 id="motivation">Motivation</h3><p>人工定位bug是想当费事的事情，因此希望使用自动执行测试的办法在执行过程中使用不同的颜色以及颜色的不同深度来映射代码的可信程度，帮助用户来定位bug</p><h3 id="evalution">Evalution</h3><h3 id="details">Details</h3>]]></content>
    
    <summary type="html">
    
      James A. Jones, Mary Jean Harrold, and John Stasko. Visualization of test information to assist fault localization. ICSE&#39;02
    
    </summary>
    
    
      <category term="paper" scheme="https://wym0120.github.io/categories/paper/"/>
    
    
      <category term="Software Maintence and Evolution" scheme="https://wym0120.github.io/tags/Software-Maintence-and-Evolution/"/>
    
  </entry>
  
  <entry>
    <title>[ISER] [STA] AddressSanitizer: A fast address sanity checker</title>
    <link href="https://wym0120.github.io/2020/09/18/paper/ISER/Software%20Testing%20and%20Analysis/sta-4/"/>
    <id>https://wym0120.github.io/2020/09/18/paper/ISER/Software%20Testing%20and%20Analysis/sta-4/</id>
    <published>2020-09-18T10:24:23.000Z</published>
    <updated>2021-04-12T15:01:26.110Z</updated>
    
    <content type="html"><![CDATA[<h3 id="abstract">Abstract</h3><blockquote><p>Memory access bugs, including buffer overflows and uses of freed heap memory, remain a serious problem for programming languages like C and C++. Many memory error detectors exist, but most of them are either slow or detect a limited set of bugs, or both.</p></blockquote><blockquote><p>This paper presents AddressSanitizer, a new memory error detector. Our tool finds out-of-bounds accesses to heap, stack, and global objects, as well as use-after-free bugs. It employs a specialized memory allocator and code instrumentation that is simple enough to be implemented in any compiler, binary translation system, or even in hardware.</p></blockquote><blockquote><p>AddressSanitizer achieves efficiency without sacrificing comprehensiveness. Its average slowdown is just 73% yet it accurately detects bugs at the point of occurrence. It has found over 300 previously unknown bugs in the Chromium browser and many bugs in other software.</p></blockquote><h3 id="总体评价">总体评价</h3><h3 id="motivation">Motivation</h3><p>目前检测边界溢出和访问已释放问题的工具要么不够快要么开销太大（好简单粗暴</p><h3 id="evalution">Evalution</h3><h3 id="details">Details</h3>]]></content>
    
    <summary type="html">
    
      Konstantin Serebryany, Derek Bruening, Alexander Potapenko, and Dmitry Vyukov. AddressSanitizer: A fast address sanity checker. USENIX ATC&#39;12
    
    </summary>
    
    
      <category term="paper" scheme="https://wym0120.github.io/categories/paper/"/>
    
    
      <category term="Software Testing and Analysis" scheme="https://wym0120.github.io/tags/Software-Testing-and-Analysis/"/>
    
  </entry>
  
  <entry>
    <title>[ISER] [STA] A lightweight, general system for finding serious storage system errors</title>
    <link href="https://wym0120.github.io/2020/09/18/paper/ISER/Software%20Testing%20and%20Analysis/sta-3/"/>
    <id>https://wym0120.github.io/2020/09/18/paper/ISER/Software%20Testing%20and%20Analysis/sta-3/</id>
    <published>2020-09-18T10:24:20.000Z</published>
    <updated>2021-04-12T15:01:26.110Z</updated>
    
    <content type="html"><![CDATA[<h3 id="abstract">Abstract</h3><blockquote><p>Storage systems such as file systems, databases, and RAID systems have a simple, basic contract: you give them data, they do not lose or corrupt it. Often they store the only copy, making its irrevocable loss almost arbitrarily bad. Unfortunately, their code is exceptionally hard to get right, since it must correctly recover from any crash at any program point, no matter how their state was smeared across volatile and persistent memory.</p></blockquote><blockquote><p>This paper describes EXPLODE, a system that makes it easy to systematically check real storage systems for errors. It takes user-written, potentially system-specific checkers and uses them to drive a storage system into tricky corner cases, including crash recovery errors. EXPLODE uses a novel adaptation of ideas from model checking, a comprehensive, heavyweight formal verification technique, that makes its checking more systematic (and hopefully more effective) than a pure testing approach while being just as lightweight.</p></blockquote><blockquote><p>EXPLODE is effective. It found serious bugs in a broad range of real storage systems (without requiring source code): three version control systems, Berkeley DB, an NFS implementation, ten file systems, a RAID system, and the popular VMware GSX virtual machine. We found bugs in every system we checked, 36 bugs in total, typically with little effort.</p></blockquote><p>keywords:</p><h3 id="总体评价">总体评价</h3><h3 id="motivation">Motivation</h3><p>文件系统中会有各种各样的机制来预防崩溃，而如果这些机制中也出现了bug，那会是十分严重的。但是目前已有的工作检测文件系统中的bug的方法还是非常的原始和低效的，因此就开发了一个新的工具（严重缺乏操作系统关于文件系统的知识，很多地方没看懂） ### Evalution</p><h3 id="details">Details</h3>]]></content>
    
    <summary type="html">
    
      Junfeng Yang, Can Sar, and Dawson Engler. eXplode: A lightweight, general system for finding serious storage system errors. OSDI&#39;06
    
    </summary>
    
    
      <category term="paper" scheme="https://wym0120.github.io/categories/paper/"/>
    
    
      <category term="Software Testing and Analysis" scheme="https://wym0120.github.io/tags/Software-Testing-and-Analysis/"/>
    
  </entry>
  
  <entry>
    <title>[ISER] [STA] Dynamically discovering likely program invariants to support program evolution</title>
    <link href="https://wym0120.github.io/2020/09/18/paper/ISER/Software%20Testing%20and%20Analysis/sta-1/"/>
    <id>https://wym0120.github.io/2020/09/18/paper/ISER/Software%20Testing%20and%20Analysis/sta-1/</id>
    <published>2020-09-18T10:24:15.000Z</published>
    <updated>2021-04-12T15:01:26.110Z</updated>
    
    <content type="html"><![CDATA[<h3 id="abstract">Abstract</h3><blockquote><p>Explicitly stated program invariants can help programmers by identifying program properties that must be preserved when modifying code. In practice, however, these invariants are usually implicit. An alternative to expecting programmers to fully annotate code with invariants is to automatically infer likely invariants from the program itself. This research focuses on dynamic techniques for discovering invariants from execution traces.</p></blockquote><blockquote><p>This article reports three results. First, it describes techniques for dynamically discovering invariants,along with an implementation, named Daikon, that embodies these techniques. Second, it reports on theapplication of Daikon to two sets of target programs. In programs from Gries's work on program derivation,the system rediscovered predened invariants. In a C program lacking explicit invariants, the system discovered invariants that assisted a software evolution task. These experiments demonstrate that, at least forsmall programs, invariant inference is both accurate and useful. Third, it analyzes scalability issues such asinvariant detection runtime and accuracy as functions of test suites and program points instrumented.</p></blockquote><p>keywords: Program invariants, formal specication, software evolution, dynamic analysis, execution traces, logical inference, pattern recognition</p><h3 id="总体评价">总体评价</h3><h3 id="motivation">Motivation</h3><p>不变式在程序开发的过程中是十分重要的，它能够保证程序不会因为修改代码而破坏原有的代码正确性。但是大多数时候不变式都是非显式的，这篇文章就想通过追踪变量值的变化来动态的推导出不变式。</p><h3 id="evalution">Evalution</h3><h3 id="details">Details</h3>]]></content>
    
    <summary type="html">
    
      Michael D. Ernst, Jake Cockrell, William G. Griswold, and David Notkin. Dynamically discovering likely program invariants to support program evolution. IEEE Transactions on Software Engineering (TSE), 27(2), 2001
    
    </summary>
    
    
      <category term="paper" scheme="https://wym0120.github.io/categories/paper/"/>
    
    
      <category term="Software Testing and Analysis" scheme="https://wym0120.github.io/tags/Software-Testing-and-Analysis/"/>
    
  </entry>
  
  <entry>
    <title>[课堂笔记] 软件工程研究入门</title>
    <link href="https://wym0120.github.io/2020/09/18/lecture/iser/iser-notes/"/>
    <id>https://wym0120.github.io/2020/09/18/lecture/iser/iser-notes/</id>
    <published>2020-09-18T02:10:16.000Z</published>
    <updated>2021-04-12T15:01:26.106Z</updated>
    
    <content type="html"><![CDATA[<h3 id="conduct-rigorous-and-scientific-research">Conduct Rigorous And Scientific Research</h3><h4 id="写作中的presentation">写作中的presentation</h4><ul><li>前后用词一致</li><li>类似句子不要换用句式</li><li>并排枚举的时候强制加上逗号</li><li>宾语从句里面也不要省略that，例如Suppose that / We assume that</li></ul><h4 id="research-formulation">Research Formulation</h4><p>整体上来说，做科研和写论文通常是一起进行的。</p><p>关键概念：必须先定义再使用，用数学上可表达或者机器可执行的形式去定义 非关键概念：尽量把它扔掉 在同一篇论文中每个概念都需要一个很明确的指代，而不能经常变换</p><p>Research Problem 需要有明确的定义的问题边界，不要over claim</p><p>Motivating Example 找到一些有区分度的例子——已有工作在这个例子中不能做，而我们的工作可以做</p><p>Inadequacy Of Related Work 只需要展示不同点，而不要去批判</p><p>Insight 最重要的点，为什么我们的工作比相关工作做的更好</p><h4 id="experimentation">Experimentation</h4><p>Experimentation 和 Case Study的区别：实验环节是可以控制变量的，并且是在一个实验室的环境中。case study是无法控制变量的，是在实际生产环境中的结果</p><h5 id="questions-and-subjects">Questions and Subjects</h5><p>问题设置：在<strong><em>什么条件下</em></strong>通过<strong><em>什么途径</em></strong>在什么<strong><em>方面</em></strong>做得好 主体的选择是否具有代表性</p><h5 id="experimentation-design">Experimentation Design</h5><p>Variable Independent variables（factors） ： 类似与函数中的自变量 Dependent variables ：类似于函数中的应变量，是用于衡量实验结果的一些指标 Controlled variables ：由于难以控制因此一些被固定下来的值，但是这些值对实验不会产生决定性的影响</p><h5 id="threats-to-validity">Threats to Validity</h5><ul><li>constuct validity</li><li>internal validity</li><li>external validity</li><li>concluusion validity</li></ul><p>todo：看一下原文</p><h5 id="exercise-and-discussion">Exercise and discussion</h5><p>回答为什么这些threats会影响实验数据<strong><em>但是</em></strong>为什么不会影响结论的正确性</p>]]></content>
    
    <summary type="html">
    
      软件工程研究入门课堂笔记
    
    </summary>
    
    
    
      <category term="lecture notes" scheme="https://wym0120.github.io/tags/lecture-notes/"/>
    
  </entry>
  
</feed>
